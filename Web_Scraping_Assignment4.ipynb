{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all the required libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the webdriver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the url\n",
    "url='https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining variables\n",
    "rank_list=[]\n",
    "name_list=[]\n",
    "artist=[]\n",
    "date_list=[]\n",
    "views_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "#Scrape the details of most viewed videos on YouTube from Wikipedia\n",
    "#need to find following details:\n",
    "#A) Rank\n",
    "#B) Name\n",
    "#C) Artist\n",
    "#D) Upload date\n",
    "#E) Views\n",
    "\n",
    "\n",
    "#fetching the artist list\n",
    "try:\n",
    "    artists=driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[3]\")\n",
    "    for i in artists:\n",
    "        artist.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    artist.append('No details available')\n",
    "\n",
    "except StaleElementReferenceException:#handling Stale element exception\n",
    "    artist.append('No details available')\n",
    "\n",
    "print(len(artist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Pinkfong Kids' Songs & Stories\",\n",
       " 'Luis Fonsi',\n",
       " 'LooLoo Kids',\n",
       " 'Ed Sheeran',\n",
       " 'Wiz Khalifa',\n",
       " 'Get Movies',\n",
       " 'Mark Ronson',\n",
       " 'Miroshka TV',\n",
       " 'Cocomelon – Nursery Rhymes',\n",
       " 'Psy',\n",
       " 'ChuChu TV',\n",
       " 'Maroon 5',\n",
       " 'Justin Bieber',\n",
       " 'El Chombo',\n",
       " 'Katy Perry',\n",
       " 'OneRepublic',\n",
       " 'Ed Sheeran',\n",
       " 'Katy Perry',\n",
       " 'Alan Walker',\n",
       " 'Cocomelon – Nursery Rhymes',\n",
       " 'Taylor Swift',\n",
       " 'Major Lazer',\n",
       " 'Maroon 5',\n",
       " 'Enrique Iglesias',\n",
       " 'Passenger',\n",
       " 'J Balvin',\n",
       " 'Ed Sheeran',\n",
       " 'Adele',\n",
       " 'Shakira',\n",
       " 'Crazy Frog']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "#fetching the name list\n",
    "try:\n",
    "    names=driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[2]\")\n",
    "    for i in names:\n",
    "        name_list.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    name_list.append('No details available')\n",
    "\n",
    "except StaleElementReferenceException:#handling Stale element exception\n",
    "    name_list.append('No details available')\n",
    "\n",
    "print(len(name_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"Baby Shark Dance\"[22]',\n",
       " '\"Despacito\"[24]',\n",
       " '\"Johny Johny Yes Papa\"[25]',\n",
       " '\"Shape of You\"[26]',\n",
       " '\"See You Again\"[27]',\n",
       " '\"Masha and the Bear – Recipe for Disaster\"[30]',\n",
       " '\"Uptown Funk\"[31]',\n",
       " '\"Learning Colors – Colorful Eggs on a Farm\"[32]',\n",
       " '\"Bath Song\"[33]',\n",
       " '\"Gangnam Style\"[34]',\n",
       " '\"Phonics Song with Two Words\"[36]',\n",
       " '\"Sugar\"[37]',\n",
       " '\"Sorry\"[38]',\n",
       " '\"Dame Tu Cosita\"[39]',\n",
       " '\"Roar\"[40]',\n",
       " '\"Counting Stars\"[41]',\n",
       " '\"Thinking Out Loud\"[42]',\n",
       " '\"Dark Horse\"[43]',\n",
       " '\"Faded\"[44]',\n",
       " '\"Wheels on the Bus\"[45]',\n",
       " '\"Shake It Off\"[46]',\n",
       " '\"Lean On\"[47]',\n",
       " '\"Girls Like You\"[48]',\n",
       " '\"Bailando\"[49]',\n",
       " '\"Let Her Go\"[50]',\n",
       " '\"Mi Gente\"[51]',\n",
       " '\"Perfect\"[52]',\n",
       " '\"Hello\"[53]',\n",
       " '\"Waka Waka (This Time for Africa)\"[54]',\n",
       " '\"Axel F\"[55]']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "#fetching the rank list\n",
    "try:\n",
    "    rank=driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[1]\")\n",
    "    for i in rank:\n",
    "        rank_list.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    rank_list.append('No details available')\n",
    "\n",
    "except StaleElementReferenceException:#handling Stale element exception\n",
    "    rank_list.append('No details available')\n",
    "\n",
    "print(len(rank_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.',\n",
       " '2.',\n",
       " '3.',\n",
       " '4.',\n",
       " '5.',\n",
       " '6.',\n",
       " '7.',\n",
       " '8.',\n",
       " '9.',\n",
       " '10.',\n",
       " '11.',\n",
       " '12.',\n",
       " '13.',\n",
       " '14.',\n",
       " '15.',\n",
       " '16.',\n",
       " '17.',\n",
       " '18.',\n",
       " '19.',\n",
       " '20.',\n",
       " '21.',\n",
       " '22.',\n",
       " '23.',\n",
       " '24.',\n",
       " '25.',\n",
       " '26.',\n",
       " '27.',\n",
       " '28.',\n",
       " '29.',\n",
       " '30.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "#fetching the upload date list\n",
    "try:\n",
    "    date=driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[5]\")\n",
    "    for i in date:\n",
    "        date_list.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    date_list.append('No details available')\n",
    "\n",
    "except StaleElementReferenceException:#handling Stale element exception\n",
    "    date_list.append('No details available')\n",
    "\n",
    "print(len(date_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['June 17, 2016',\n",
       " 'January 12, 2017',\n",
       " 'October 8, 2016',\n",
       " 'January 30, 2017',\n",
       " 'April 6, 2015',\n",
       " 'January 31, 2012',\n",
       " 'November 19, 2014',\n",
       " 'February 27, 2018',\n",
       " 'May 2, 2018',\n",
       " 'July 15, 2012',\n",
       " 'March 6, 2014',\n",
       " 'January 14, 2015',\n",
       " 'October 22, 2015',\n",
       " 'April 5, 2018',\n",
       " 'September 5, 2013',\n",
       " 'May 31, 2013',\n",
       " 'October 7, 2014',\n",
       " 'February 20, 2014',\n",
       " 'December 3, 2015',\n",
       " 'May 24, 2018',\n",
       " 'August 18, 2014',\n",
       " 'March 22, 2015',\n",
       " 'May 31, 2018',\n",
       " 'April 11, 2014',\n",
       " 'July 25, 2012',\n",
       " 'June 29, 2017',\n",
       " 'November 9, 2017',\n",
       " 'October 22, 2015',\n",
       " 'June 4, 2010',\n",
       " 'June 16, 2009']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "#fetching the views list\n",
    "try:\n",
    "    views=driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[4]\")\n",
    "    for i in views:\n",
    "        views_list.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    views_list.append('No details available')\n",
    "\n",
    "except StaleElementReferenceException:#handling Stale element exception\n",
    "    views_list.append('No details available')\n",
    "\n",
    "print(len(views_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8.74',\n",
       " '7.39',\n",
       " '5.43',\n",
       " '5.34',\n",
       " '5.13',\n",
       " '4.44',\n",
       " '4.20',\n",
       " '4.14',\n",
       " '4.12',\n",
       " '4.08',\n",
       " '3.91',\n",
       " '3.48',\n",
       " '3.44',\n",
       " '3.38',\n",
       " '3.36',\n",
       " '3.31',\n",
       " '3.27',\n",
       " '3.08',\n",
       " '3.08',\n",
       " '3.07',\n",
       " '3.06',\n",
       " '3.05',\n",
       " '3.04',\n",
       " '3.04',\n",
       " '3.00',\n",
       " '2.93',\n",
       " '2.86',\n",
       " '2.84',\n",
       " '2.84',\n",
       " '2.83']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "views_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the webdriver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the url\n",
    "url='https://www.bcci.tv/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Locating the search_button to click(clicking the word 'international')\n",
    "search_button=driver.find_element_by_xpath('//div[@class=\"navigation__link navigation__link--has-drop-down js-navigation-link\"]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Locating the search_button to click the word 'fixture' \n",
    "search_button_next=driver.find_element_by_xpath('//a[@class=\"navigation__link navigation__link--in-drop-down\"]')\n",
    "search_button_next.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining variables\n",
    "match_title=[]\n",
    "series_list=[]\n",
    "place_list=[]\n",
    "date_time_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching the match titles\n",
    "for i in range(0,1):\n",
    "    try:\n",
    "        for j in driver.find_elements_by_xpath('//strong[@class=\"fixture__name fixture__name--with-margin\"]'):\n",
    "            match_title.append(j.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        match_title.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Final', '1st Test', '2nd Test', '3rd Test', '4th Test', '5th Test']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching the series list\n",
    "for i in range(0,1):\n",
    "    try:\n",
    "        for k in driver.find_elements_by_xpath('//span[@class=\"u-unskewed-text fixture__tournament-label u-truncated\"]'):\n",
    "            series_list.append(k.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        series_list.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ICC WORLD TEST CHAMPIONSHIP',\n",
       " 'ENGLAND V INDIA 2021',\n",
       " 'ENGLAND V INDIA 2021',\n",
       " 'ENGLAND V INDIA 2021',\n",
       " 'ENGLAND V INDIA 2021',\n",
       " 'ENGLAND V INDIA 2021']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching the place list\n",
    "for i in range(0,1):\n",
    "    try:\n",
    "        for l in driver.find_elements_by_xpath('//p[@class=\"fixture__additional-info\"]/span'):\n",
    "            place_list.append(l.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        place_list.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Ageas Bowl, Southampton',\n",
       " 'Trent Bridge, Nottingham',\n",
       " \"Lord's, London\",\n",
       " 'Headingley, Leeds',\n",
       " 'The Oval, London',\n",
       " 'Old Trafford, Manchester']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "place_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching the date and time list\n",
    "for i in range(0,1):\n",
    "    try:\n",
    "        for m in driver.find_elements_by_xpath('//span[@class=\"fixture__datetime tablet-only\"]'):\n",
    "            date_time_list.append(m.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        date_time_list.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Friday 18 June 15:00 IST',\n",
       " 'Wednesday 4 August 15:30 IST',\n",
       " 'Thursday 12 August 15:30 IST',\n",
       " 'Wednesday 25 August 15:30 IST',\n",
       " 'Thursday 2 September 15:30 IST',\n",
       " 'Friday 10 September 15:30 IST']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_time_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape the details of selenium exception from guru99.com.\n",
    "#Need to find following details:\n",
    "#A) Name\n",
    "#B) Description\n",
    "\n",
    "#Lets first connect to the webdriver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the url\n",
    "url='https://www.guru99.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the url for selenium exception from guru99.com\n",
    "url='https://www.guru99.com/exception-handling-selenium.html'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining variables\n",
    "name_list=[]\n",
    "description_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching the title\n",
    "for i in range(0,1):\n",
    "    try:\n",
    "        for j in driver.find_elements_by_xpath('//div[@class=\"page-header\"]'):\n",
    "            name_list.append(j.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        name_list.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Selenium Exception Handling (Common Exceptions List)']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching the description\n",
    "for i in range(0,1):\n",
    "    try:\n",
    "        for k in driver.find_elements_by_xpath('//table[@class=\"table table-striped\"]'):\n",
    "            description_list.append(k.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        description_list.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Exception name Description\\nElementNotVisibleException This type of Selenium exception occurs when an existing element in DOM has a feature set as hidden.\\nElementNotSelectableException This Selenium exception occurs when an element is presented in the DOM, but you can be able to select. Therefore, it is not possible to interact.\\nNoSuchElementException This Exception occurs if an element could not be found.\\nNoSuchFrameException This Exception occurs if the frame target to be switched to does not exist.\\nNoAlertPresentException This Exception occurs when you switch to no presented alert.\\nNoSuchWindowException This Exception occurs if the window target to be switch does not exist.\\nStaleElementReferenceException This Selenium exception occurs happens when the web element is detached from the current DOM.\\nSessionNotFoundException The WebDriver is acting after you quit the browser.\\nTimeoutException Thrown when there is not enough time for a command to be completed. For Example, the element searched wasn't found in the specified time.\\nWebDriverException This Exception takes place when the WebDriver is acting right after you close the browser.\\nConnectionClosedException This type of Exception takes place when there is a disconnection in the driver.\\nElementClickInterceptedException The command may not be completed as the element receiving the events is concealing the element which was requested clicked.\\nElementNotInteractableException This Selenium exception is thrown when any element is presented in the DOM. However, it is impossible to interact with such an element.\\nErrorInResponseException This happens while interacting with the Firefox extension or the remote driver server.\\nErrorHandler.UnknownServerException Exception is used as a placeholder in case if the server returns an error without a stack trace.\\nImeActivationFailedException This expectation will occur when IME engine activation has failed.\\nImeNotAvailableException It takes place when IME support is unavailable.\\nInsecureCertificateException Navigation made the user agent to hit a certificate warning. This can cause by an invalid or expired TLS certificate.\\nInvalidArgumentException It occurs when an argument does not belong to the expected type.\\nInvalidCookieDomainException This happens when you try to add a cookie under a different domain instead of current URL.\\nInvalidCoordinatesException This type of Exception matches an interacting operation that is not valid.\\nInvalidElementStateExceptio It occurs when command can't be finished when the element is invalid.\\nInvalidSessionIdException This Exception took place when the given session ID is not included in the list of active sessions. It means the session does not exist or is inactive either.\\nInvalidSwitchToTargetException This occurs when the frame or window target to be switched does not exist.\\nJavascriptException This issue occurs while executing JavaScript given by the user.\\nJsonException It occurs when you afford to get the session when the session is not created.\\nNoSuchAttributeException This kind of Exception occurs when the attribute of an element could not be found.\\nMoveTargetOutOfBoundsException It takes place if the target provided to the ActionChains move() methodology is not valid. For Example, out of the document.\\nNoSuchContextException ContextAware does mobile device testing.\\nNoSuchCookieException This Exception occurs when no cookie matching with the given pathname found for all the associated cookies of the currently browsing document.\\nNotFoundException This Exception is a subclass of WebDriverException. This will occur when an element on the DOM does not exist.\\nRemoteDriverServerException This Selenium exception is thrown when the server is not responding because of the problem that the capabilities described are not proper.\\nScreenshotException It is not possible to capture a screen.\\nSessionNotCreatedException It happens when a new session could not be successfully created.\\nUnableToSetCookieException This occurs if a driver is unable to set a cookie.\\nUnexpectedTagNameException Happens if a support class did not get a web element as expected.\\nUnhandledAlertException This expectation occurs when there is an alert, but WebDriver is not able to perform Alert operation.\\nUnexpectedAlertPresentException It occurs when there is the appearance of an unexpected alert.\\nUnknownMethodException This Exception happens when the requested command matches with a known URL but and not matching with a methodology for a specific URL.\\nUnreachableBrowserException This Exception occurs only when the browser is not able to be opened or crashed because of some reason.\\nUnsupportedCommandException This occurs when remote WebDriver does n't send valid commands as expected.\"]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "#We have to find following details:\n",
    "#A) Rank\n",
    "#B) State\n",
    "#C) GSDP(18-19)\n",
    "#D) GSDP(17-18)\n",
    "#E) Share(2017)\n",
    "#F) GDP($ billion)\n",
    "\n",
    "\n",
    "#Lets first connect to the webdriver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the url\n",
    "url='http://statisticstimes.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Locating the search_button to click the word 'economy'\n",
    "search_button=driver.find_elements_by_xpath('//button[@class=\"dropbtn\"]')[1].click()\n",
    "#search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining variables\n",
    "odd_list=[]\n",
    "even_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching the rank list\n",
    "for i in range(0,1):\n",
    "    try:\n",
    "        for j in driver.find_elements_by_xpath('//tr[@class=\"odd\"]'):\n",
    "            odd_list.append(j.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        odd_list.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 Maharashtra - 2,632,792 13.94% 399.921 - 2,039,074',\n",
       " '3 Uttar Pradesh 1,687,818 1,584,764 8.39% 240.726 1,166,817 1,123,982',\n",
       " '5 Karnataka 1,631,977 1,493,127 7.91% 226.806 1,156,039 1,091,077',\n",
       " '7 Rajasthan 1,020,989 942,586 4.99% 143.179 711,627 677,428',\n",
       " '9 Telangana 969,604 861,031 4.56% 130.791 663,258 612,828',\n",
       " '11 Kerala - 781,653 4.14% 118.733 - 559,412',\n",
       " '13 Haryana 831,610 734,163 3.89% 111.519 572,240 531,085',\n",
       " '15 Punjab 574,760 526,376 2.79% 79.957 418,868 397,669',\n",
       " '17 Assam - 315,881 1.67% 47.982 - 234,048',\n",
       " '19 Jharkhand 328,598 297,204 1.57% 45.145 240,036 224,986',\n",
       " '21 Jammu & Kashmir - 155,956 0.83% 23.690 - 112,755',\n",
       " '23 Goa 80,449 73,170 0.39% 11.115 63,408 57,787',\n",
       " '25 Chandigarh - 42,114 0.22% 6.397 - 31,192',\n",
       " '27 Meghalaya 36,572 33,481 0.18% 5.086 26,695 24,682',\n",
       " '29 Manipur 31,790 27,870 0.15% 4.233 20,673 19,300',\n",
       " '31 Arunachal Pradesh - 24,603 0.13% 3.737 - 16,676',\n",
       " '33 Andaman & Nicobar Islands - - - - - -']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rank,State,GSDP(19-20),GSDP(18-19),Share(2017),GDP($billion),GSDP(cr INR)\n",
    "odd_list[:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching the state list\n",
    "for i in range(0,1):\n",
    "    try:\n",
    "        for k in driver.find_elements_by_xpath('//tr[@class=\"even\"]'):\n",
    "            even_list.append(k.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        even_list.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2 Tamil Nadu 1,845,853 1,630,208 8.63% 247.629 1,312,929 1,215,307',\n",
       " '4 Gujarat - 1,502,899 7.96% 228.290 - 1,186,379',\n",
       " '6 West Bengal 1,253,832 1,089,898 5.77% 165.556 793,223 739,525',\n",
       " '8 Andhra Pradesh 972,782 862,957 4.57% 131.083 672,018 621,301',\n",
       " '10 Madhya Pradesh 906,672 809,592 4.29% 122.977 561,801 522,009',\n",
       " '12 Delhi 856,112 774,870 4.10% 117.703 634,408 590,569',\n",
       " '14 Bihar 611,804 530,363 2.81% 80.562 414,977 375,651',\n",
       " '16 Odisha 521,275 487,805 2.58% 74.098 396,499 376,877',\n",
       " '18 Chhattisgarh 329,180 304,063 1.61% 46.187 243,477 231,182',\n",
       " '20 Uttarakhand - 245,895 1.30% 37.351 - 193,273',\n",
       " '22 Himachal Pradesh 165,472 153,845 0.81% 23.369 124,403 117,851',\n",
       " '24 Tripura 55,984 49,845 0.26% 7.571 40,583 36,963',\n",
       " '26 Puducherry 38,253 34,433 0.18% 5.230 25,093 23,013',\n",
       " '28 Sikkim 32,496 28,723 0.15% 4.363 20,017 18,722',\n",
       " '30 Nagaland - 27,283 0.14% 4.144 - 17,647',\n",
       " '32 Mizoram 26,503 22,287 0.12% 3.385 18,797 16,478']"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rank,State,GSDP(19-20),GSDP(18-19),Share(2017),GDP($billion),GSDP(cr INR)\n",
    "even_list[:16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape the details of trending repositories on Github.com.\n",
    "#Url = https://github.com/\n",
    "#We have to find the following details:\n",
    "#A) Repository title\n",
    "#B) Repository description\n",
    "#C) Contributors count\n",
    "#D) Language used\n",
    "\n",
    "#Lets first connect to the webdriver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the url\n",
    "url='https://github.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Locating the search_button to click the word 'explore'\n",
    "search_button=driver.find_elements_by_xpath('//summary[@class=\"HeaderMenu-summary HeaderMenu-link px-0 py-3 border-0 no-wrap d-block d-lg-inline-block\"]')[1].click()\n",
    "#search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Locating the search_button to click the word 'trending'from 'explore'\n",
    "search_btn=driver.find_elements_by_xpath('//ul[@class=\"list-style-none mb-3\"]/li/a')[3].click()\n",
    "#search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining variables\n",
    "title_list=[]\n",
    "description_list=[]\n",
    "count_list=[]\n",
    "language_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching the repository title list\n",
    "for i in range(0,1):\n",
    "    try:\n",
    "        for j in driver.find_elements_by_xpath('//h1[@class=\"h3 lh-condensed\"]'):\n",
    "            title_list.append(j.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        title_list.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jwasham / coding-interview-university',\n",
       " 'bitcoin / bitcoin',\n",
       " 'PaperMC / Paper',\n",
       " 'jina-ai / jina',\n",
       " 'neovim / neovim',\n",
       " 'Genymobile / scrcpy',\n",
       " 'JDHelloWorld / jd_scripts',\n",
       " 'star261 / jd',\n",
       " 'maziarraissi / Applied-Deep-Learning',\n",
       " 'github / docs',\n",
       " 'SuMaiKaDe / bot',\n",
       " 'ashishpatel26 / 500-AI-Machine-learning-Deep-learning-Computer-vision-NLP-Projects-with-code',\n",
       " 'iptv-org / iptv',\n",
       " 'whittlem / pycryptobot',\n",
       " 'GaloyMoney / galoy',\n",
       " 'biancangming / wtv',\n",
       " 'adrianhajdin / portfolio_website',\n",
       " 'nushell / nushell',\n",
       " 'MuriungiPatrick / Bootstrap-5-portfolio-template',\n",
       " 'kamranahmedse / developer-roadmap',\n",
       " 'alpinejs / alpine',\n",
       " 'actions / virtual-environments',\n",
       " 'jklepatch / eattheblocks',\n",
       " 'MichMich / MagicMirror',\n",
       " 'mit-pdos / xv6-riscv']"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching the repository description list\n",
    "for i in range(0,1):\n",
    "    try:\n",
    "        for k in driver.find_elements_by_xpath('//p[@class=\"col-9 color-text-secondary my-1 pr-4\"]'):\n",
    "            description_list.append(k.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        description_list.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A complete computer science study plan to become a software engineer.',\n",
       " 'Bitcoin Core integration/staging tree',\n",
       " 'High performance Spigot fork that aims to fix gameplay and mechanics inconsistencies',\n",
       " 'An easier way to build neural search on the cloud',\n",
       " 'Vim-fork focused on extensibility and usability',\n",
       " 'Display and control your Android device',\n",
       " 'Applied Deep Learning',\n",
       " 'The open-source repo for docs.github.com',\n",
       " '500 AI Machine learning Deep learning Computer vision NLP Projects with code',\n",
       " 'Collection of publicly available IPTV channels from all over the world',\n",
       " 'Python Crypto Bot',\n",
       " '解决电脑、手机看电视直播的苦恼，收集各种直播源，电视直播网站',\n",
       " 'Tutorial created by Enyel Sequeira, taught by JavaScript Mastery',\n",
       " 'A new type of shell',\n",
       " 'Learning Bootstrap 5 with SASS',\n",
       " 'Roadmap to becoming a web developer in 2021',\n",
       " 'A rugged, minimal framework for composing JavaScript behavior in your markup.',\n",
       " 'GitHub Actions virtual environments',\n",
       " 'Source code for Eat The Blocks, a screencast for Ethereum Dapp Developers',\n",
       " 'MagicMirror² is an open source modular smart mirror platform. With a growing list of installable modules, the MagicMirror² allows you to convert your hallway or bathroom mirror into your personal assistant.',\n",
       " 'Xv6 for RISC-V']"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching the contributors count list\n",
    "for i in range(0,1):\n",
    "    try:\n",
    "        for l in driver.find_elements_by_xpath('//a[@class=\"Link--muted d-inline-block mr-3\"]'):\n",
    "            count_list.append(l.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        count_list.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['179,542',\n",
       " '48,585',\n",
       " '54,884',\n",
       " '29,124',\n",
       " '3,967',\n",
       " '1,017',\n",
       " '5,034',\n",
       " '494',\n",
       " '44,549',\n",
       " '3,268',\n",
       " '50,214',\n",
       " '5,183',\n",
       " '261',\n",
       " '106',\n",
       " '141',\n",
       " '71',\n",
       " '934',\n",
       " '133',\n",
       " '4,474',\n",
       " '18,904',\n",
       " '158',\n",
       " '68',\n",
       " '6,162',\n",
       " '1,822',\n",
       " '35,090',\n",
       " '2,232',\n",
       " '630',\n",
       " '217',\n",
       " '102',\n",
       " '14',\n",
       " '2,358',\n",
       " '378',\n",
       " '187',\n",
       " '24',\n",
       " '11,721',\n",
       " '592',\n",
       " '127',\n",
       " '37',\n",
       " '162,744',\n",
       " '23,554',\n",
       " '16,821',\n",
       " '680',\n",
       " '3,424',\n",
       " '1,213',\n",
       " '1,363',\n",
       " '1,190',\n",
       " '14,832',\n",
       " '3,601',\n",
       " '1,439',\n",
       " '393']"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching the language list\n",
    "for i in range(0,1):\n",
    "    try:\n",
    "        for m in driver.find_elements_by_xpath('//span[@class=\"d-inline-block ml-0 mr-3\"]'):\n",
    "            language_list.append(m.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        language_list.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C++',\n",
       " 'Shell',\n",
       " 'Python',\n",
       " 'Vim script',\n",
       " 'C',\n",
       " 'JavaScript',\n",
       " 'JavaScript',\n",
       " 'JavaScript',\n",
       " 'Python',\n",
       " 'JavaScript',\n",
       " 'Python',\n",
       " 'TypeScript',\n",
       " 'Python',\n",
       " 'JavaScript',\n",
       " 'Rust',\n",
       " 'JavaScript',\n",
       " 'HTML',\n",
       " 'PowerShell',\n",
       " 'JavaScript',\n",
       " 'JavaScript',\n",
       " 'C']"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape the details of top 100 songs on billiboard.com.\n",
    "#Url = https://www.billboard.com/\n",
    "#We have to find the following details:\n",
    "#A) Song name\n",
    "#B) Artist name\n",
    "#C) Last week rank\n",
    "#D) Peak rank\n",
    "#E) Weeks on board\n",
    "\n",
    "#Lets first connect to the webdriver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the url\n",
    "url='https://www.billboard.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Locating the search_button to click\n",
    "search_button=driver.find_element_by_id(\"toggle-menu-action\").click()\n",
    "#search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Locating the search_button to click the word 'Chart'\n",
    "search_btn=driver.find_elements_by_xpath('//div[@class=\"header__main-menu__wrapper flex--grow\"]/ul/li')[0].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Locating the search button to click 'hot 100'\n",
    "search_switch=driver.find_elements_by_xpath('//ul[@class=\"header__submenu__list\"]/li/a')[0].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining variables\n",
    "song=[]\n",
    "artist=[]\n",
    "lwr=[] #Last week rank\n",
    "pr=[] #Peak rank\n",
    "wob=[] #weeks on board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "#fetching the songs list\n",
    "try:\n",
    "    songs=driver.find_elements_by_xpath(\"//span[@class='chart-element__information__song text--truncate color--primary']\")\n",
    "    for i in songs:\n",
    "        song.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    song.append('No details available')\n",
    "\n",
    "except StaleElementReferenceException:#handling Stale element exception\n",
    "    song.append('No details available')\n",
    "\n",
    "print(len(song))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Butter',\n",
       " 'Good 4 U',\n",
       " 'Levitating',\n",
       " 'Peaches',\n",
       " 'Leave The Door Open',\n",
       " 'Save Your Tears',\n",
       " 'Kiss Me More',\n",
       " 'Astronaut In The Ocean',\n",
       " 'Deja Vu',\n",
       " 'Yonaguni',\n",
       " 'Montero (Call Me By Your Name)',\n",
       " 'Without You',\n",
       " 'Forever After All',\n",
       " 'Rapstar',\n",
       " 'Blinding Lights',\n",
       " 'Hats Off',\n",
       " 'Drivers License',\n",
       " 'Beautiful Mistakes',\n",
       " 'Traitor',\n",
       " 'Late At Night',\n",
       " 'Voice Of The Heroes',\n",
       " 'Best Friend',\n",
       " 'Heartbreak Anniversary',\n",
       " 'Heat Waves',\n",
       " 'Calling My Phone',\n",
       " 'Favorite Crime',\n",
       " 'Lost Cause',\n",
       " 'Happier',\n",
       " 'Up',\n",
       " 'Mood',\n",
       " '2040',\n",
       " 'Every Chance I Get',\n",
       " 'Telepatia',\n",
       " 'How It Feels',\n",
       " 'Brutal',\n",
       " 'Wockesha',\n",
       " 'Wants And Needs',\n",
       " 'Famous Friends',\n",
       " 'pov',\n",
       " 'Gone',\n",
       " 'Beat Box',\n",
       " \"My Ex's Best Friend\",\n",
       " 'Still Runnin',\n",
       " 'Track Star',\n",
       " 'What You Know Bout Love',\n",
       " 'Who I Want',\n",
       " 'my.life',\n",
       " 'Back In Blood',\n",
       " 'Time Today',\n",
       " 'Lil Bit',\n",
       " 'Blame It On You',\n",
       " 'Nobody',\n",
       " 'Todo de Ti',\n",
       " 'Enough For You',\n",
       " 'Settling Down',\n",
       " 'Still Hood',\n",
       " 'Jealousy, Jealousy',\n",
       " 'Okay',\n",
       " 'Almost Maybes',\n",
       " 'Man Of My Word',\n",
       " 'Build A Bitch',\n",
       " \"Breaking Up Was Easy In The 90's\",\n",
       " 'Glad You Exist',\n",
       " 'pride.is.the.devil',\n",
       " '1 Step Forward, 3 Steps Back',\n",
       " 'Ski',\n",
       " 'Medical',\n",
       " 'Rich Off Pain',\n",
       " 'Leave Before You Love Me',\n",
       " 'Lying',\n",
       " 'Snowflakes',\n",
       " 'Single Saturday Night',\n",
       " \"That's Facts\",\n",
       " 'Made For You',\n",
       " 'Your Power',\n",
       " 'No More Parties',\n",
       " \"We're Good\",\n",
       " 'One Too Many',\n",
       " 'Please',\n",
       " 'Up The Side',\n",
       " 'Minimum Wage',\n",
       " 'Miss The Rage',\n",
       " 'Way Less Sad',\n",
       " 'Hope Ur OK',\n",
       " 'Quicksand',\n",
       " 'Arcade',\n",
       " 'Straightenin',\n",
       " 'Gang Gang',\n",
       " \"Drinkin' Beer. Talkin' God. Amen.\",\n",
       " 'Follow You',\n",
       " 'Chasing After You',\n",
       " 'Tell Em',\n",
       " '4 Da Gang',\n",
       " 'Tombstone',\n",
       " \"What's Next\",\n",
       " 'Things A Man Oughta Know',\n",
       " 'Country Again',\n",
       " \"Drunk (And I Don't Wanna Go Home)\",\n",
       " 'If You Want To',\n",
       " 'Seeing Green']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "#fetching the artists list\n",
    "try:\n",
    "    artists=driver.find_elements_by_xpath(\"//span[@class='chart-element__information__artist text--truncate color--secondary']\")\n",
    "    for i in artists:\n",
    "        artist.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    artist.append('No details available')\n",
    "\n",
    "except StaleElementReferenceException:#handling Stale element exception\n",
    "    artist.append('No details available')\n",
    "\n",
    "print(len(artist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BTS',\n",
       " 'Olivia Rodrigo',\n",
       " 'Dua Lipa Featuring DaBaby',\n",
       " 'Justin Bieber Featuring Daniel Caesar & Giveon',\n",
       " 'Silk Sonic (Bruno Mars & Anderson .Paak)',\n",
       " 'The Weeknd & Ariana Grande',\n",
       " 'Doja Cat Featuring SZA',\n",
       " 'Masked Wolf',\n",
       " 'Olivia Rodrigo',\n",
       " 'Bad Bunny',\n",
       " 'Lil Nas X',\n",
       " 'The Kid LAROI',\n",
       " 'Luke Combs',\n",
       " 'Polo G',\n",
       " 'The Weeknd',\n",
       " 'Lil Baby, Lil Durk & Travis Scott',\n",
       " 'Olivia Rodrigo',\n",
       " 'Maroon 5 Featuring Megan Thee Stallion',\n",
       " 'Olivia Rodrigo',\n",
       " 'Roddy Ricch',\n",
       " 'Lil Baby & Lil Durk',\n",
       " 'Saweetie Featuring Doja Cat',\n",
       " 'Giveon',\n",
       " 'Glass Animals',\n",
       " 'Lil Tjay Featuring 6LACK',\n",
       " 'Olivia Rodrigo',\n",
       " 'Billie Eilish',\n",
       " 'Olivia Rodrigo',\n",
       " 'Cardi B',\n",
       " '24kGoldn Featuring iann dior',\n",
       " 'Lil Baby & Lil Durk',\n",
       " 'DJ Khaled Featuring Lil Baby & Lil Durk',\n",
       " 'Kali Uchis',\n",
       " 'Lil Baby & Lil Durk',\n",
       " 'Olivia Rodrigo',\n",
       " 'Moneybagg Yo',\n",
       " 'Drake Featuring Lil Baby',\n",
       " 'Chris Young + Kane Brown',\n",
       " 'Ariana Grande',\n",
       " 'Dierks Bentley',\n",
       " 'SpotemGottem Featuring Pooh Shiesty Or DaBaby',\n",
       " 'Machine Gun Kelly X blackbear',\n",
       " 'Lil Baby, Lil Durk & Meek Mill',\n",
       " 'Mooski',\n",
       " 'Pop Smoke',\n",
       " 'Lil Baby & Lil Durk',\n",
       " 'J. Cole, 21 Savage & Morray',\n",
       " 'Pooh Shiesty Featuring Lil Durk',\n",
       " 'Moneybagg Yo',\n",
       " 'Nelly & Florida Georgia Line',\n",
       " 'Jason Aldean',\n",
       " 'Dylan Scott',\n",
       " 'Rauw Alejandro',\n",
       " 'Olivia Rodrigo',\n",
       " 'Miranda Lambert',\n",
       " 'Lil Baby & Lil Durk',\n",
       " 'Olivia Rodrigo',\n",
       " 'Lil Baby & Lil Durk',\n",
       " 'Jordan Davis',\n",
       " 'Lil Baby & Lil Durk',\n",
       " 'Bella Poarch',\n",
       " 'Sam Hunt',\n",
       " 'Dan + Shay',\n",
       " 'J. Cole & Lil Baby',\n",
       " 'Olivia Rodrigo',\n",
       " 'Young Thug & Gunna',\n",
       " 'Lil Baby & Lil Durk',\n",
       " 'Lil Baby, Lil Durk & Rod Wave',\n",
       " 'Marshmello X Jonas Brothers',\n",
       " 'Lil Baby & Lil Durk',\n",
       " 'Tom MacDonald',\n",
       " 'Cole Swindell',\n",
       " 'Lil Baby & Lil Durk',\n",
       " 'Jake Owen',\n",
       " 'Billie Eilish',\n",
       " 'Coi Leray Featuring Lil Durk',\n",
       " 'Dua Lipa',\n",
       " 'Keith Urban Duet With P!nk',\n",
       " 'Lil Baby & Lil Durk',\n",
       " 'Lil Baby, Lil Durk & Young Thug',\n",
       " 'Blake Shelton',\n",
       " 'Trippie Redd & Playboi Carti',\n",
       " 'AJR',\n",
       " 'Olivia Rodrigo',\n",
       " 'Morray',\n",
       " 'Duncan Laurence',\n",
       " 'Migos',\n",
       " 'Polo G & Lil Wayne',\n",
       " 'Chase Rice Featuring Florida Georgia Line',\n",
       " 'Imagine Dragons',\n",
       " 'Ryan Hurd With Maren Morris',\n",
       " 'Cochise & $NOT',\n",
       " '42 Dugg & Roddy Ricch',\n",
       " 'Rod Wave',\n",
       " 'Drake',\n",
       " 'Lainey Wilson',\n",
       " 'Thomas Rhett',\n",
       " 'Elle King & Miranda Lambert',\n",
       " 'Lil Baby & Lil Durk',\n",
       " 'Nicki Minaj, Drake & Lil Wayne']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "#fetching the last week rank list\n",
    "try:\n",
    "    lastweek=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--last']\")\n",
    "    for i in lastweek:\n",
    "        lwr.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    lwr.append('No details available')\n",
    "\n",
    "except StaleElementReferenceException:#handling Stale element exception\n",
    "    lwr.append('No details available')\n",
    "\n",
    "print(len(lwr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '2',\n",
       " '3',\n",
       " '6',\n",
       " '4',\n",
       " '5',\n",
       " '7',\n",
       " '9',\n",
       " '8',\n",
       " '-',\n",
       " '10',\n",
       " '11',\n",
       " '15',\n",
       " '14',\n",
       " '17',\n",
       " '-',\n",
       " '13',\n",
       " '18',\n",
       " '12',\n",
       " '-',\n",
       " '81',\n",
       " '22',\n",
       " '23',\n",
       " '25',\n",
       " '21',\n",
       " '16',\n",
       " '-',\n",
       " '20',\n",
       " '24',\n",
       " '30',\n",
       " '-',\n",
       " '26',\n",
       " '34',\n",
       " '-',\n",
       " '19',\n",
       " '33',\n",
       " '39',\n",
       " '43',\n",
       " '37',\n",
       " '36',\n",
       " '29',\n",
       " '31',\n",
       " '-',\n",
       " '32',\n",
       " '41',\n",
       " '-',\n",
       " '28',\n",
       " '35',\n",
       " '48',\n",
       " '53',\n",
       " '63',\n",
       " '50',\n",
       " '66',\n",
       " '27',\n",
       " '47',\n",
       " '-',\n",
       " '42',\n",
       " '-',\n",
       " '51',\n",
       " '-',\n",
       " '56',\n",
       " '49',\n",
       " '68',\n",
       " '45',\n",
       " '38',\n",
       " '55',\n",
       " '-',\n",
       " '-',\n",
       " '72',\n",
       " '-',\n",
       " '-',\n",
       " '70',\n",
       " '-',\n",
       " '57',\n",
       " '60',\n",
       " '59',\n",
       " '54',\n",
       " '71',\n",
       " '-',\n",
       " '-',\n",
       " '69',\n",
       " '58',\n",
       " '77',\n",
       " '52',\n",
       " '73',\n",
       " '85',\n",
       " '78',\n",
       " '61',\n",
       " '75',\n",
       " '86',\n",
       " '87',\n",
       " '64',\n",
       " '74',\n",
       " '79',\n",
       " '76',\n",
       " '93',\n",
       " '89',\n",
       " '92',\n",
       " '-',\n",
       " '67']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lwr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "#fetching the last week rank list\n",
    "try:\n",
    "    lastweek=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--last']\")\n",
    "    for i in lastweek:\n",
    "        lwr.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    lwr.append('No details available')\n",
    "\n",
    "except StaleElementReferenceException:#handling Stale element exception\n",
    "    lwr.append('No details available')\n",
    "\n",
    "print(len(lwr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '2',\n",
       " '3',\n",
       " '6',\n",
       " '4',\n",
       " '5',\n",
       " '7',\n",
       " '9',\n",
       " '8',\n",
       " '-',\n",
       " '10',\n",
       " '11',\n",
       " '15',\n",
       " '14',\n",
       " '17',\n",
       " '-',\n",
       " '13',\n",
       " '18',\n",
       " '12',\n",
       " '-',\n",
       " '81',\n",
       " '22',\n",
       " '23',\n",
       " '25',\n",
       " '21',\n",
       " '16',\n",
       " '-',\n",
       " '20',\n",
       " '24',\n",
       " '30',\n",
       " '-',\n",
       " '26',\n",
       " '34',\n",
       " '-',\n",
       " '19',\n",
       " '33',\n",
       " '39',\n",
       " '43',\n",
       " '37',\n",
       " '36',\n",
       " '29',\n",
       " '31',\n",
       " '-',\n",
       " '32',\n",
       " '41',\n",
       " '-',\n",
       " '28',\n",
       " '35',\n",
       " '48',\n",
       " '53',\n",
       " '63',\n",
       " '50',\n",
       " '66',\n",
       " '27',\n",
       " '47',\n",
       " '-',\n",
       " '42',\n",
       " '-',\n",
       " '51',\n",
       " '-',\n",
       " '56',\n",
       " '49',\n",
       " '68',\n",
       " '45',\n",
       " '38',\n",
       " '55',\n",
       " '-',\n",
       " '-',\n",
       " '72',\n",
       " '-',\n",
       " '-',\n",
       " '70',\n",
       " '-',\n",
       " '57',\n",
       " '60',\n",
       " '59',\n",
       " '54',\n",
       " '71',\n",
       " '-',\n",
       " '-',\n",
       " '69',\n",
       " '58',\n",
       " '77',\n",
       " '52',\n",
       " '73',\n",
       " '85',\n",
       " '78',\n",
       " '61',\n",
       " '75',\n",
       " '86',\n",
       " '87',\n",
       " '64',\n",
       " '74',\n",
       " '79',\n",
       " '76',\n",
       " '93',\n",
       " '89',\n",
       " '92',\n",
       " '-',\n",
       " '67']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lwr[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "#fetching the peak rank list\n",
    "try:\n",
    "    peak=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--peak']\")\n",
    "    for i in peak:\n",
    "        pr.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    pr.append('No details available')\n",
    "\n",
    "except StaleElementReferenceException:#handling Stale element exception\n",
    "    pr.append('No details available')\n",
    "\n",
    "print(len(pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '1',\n",
       " '2',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '5',\n",
       " '6',\n",
       " '3',\n",
       " '10',\n",
       " '1',\n",
       " '8',\n",
       " '2',\n",
       " '1',\n",
       " '1',\n",
       " '16',\n",
       " '1',\n",
       " '18',\n",
       " '9',\n",
       " '20',\n",
       " '21',\n",
       " '14',\n",
       " '17',\n",
       " '24',\n",
       " '3',\n",
       " '16',\n",
       " '27',\n",
       " '15',\n",
       " '1',\n",
       " '1',\n",
       " '31',\n",
       " '20',\n",
       " '33',\n",
       " '34',\n",
       " '12',\n",
       " '33',\n",
       " '2',\n",
       " '38',\n",
       " '37',\n",
       " '36',\n",
       " '12',\n",
       " '20',\n",
       " '43',\n",
       " '31',\n",
       " '9',\n",
       " '46',\n",
       " '2',\n",
       " '13',\n",
       " '31',\n",
       " '50',\n",
       " '51',\n",
       " '50',\n",
       " '53',\n",
       " '14',\n",
       " '47',\n",
       " '56',\n",
       " '24',\n",
       " '58',\n",
       " '51',\n",
       " '60',\n",
       " '56',\n",
       " '32',\n",
       " '63',\n",
       " '7',\n",
       " '19',\n",
       " '18',\n",
       " '67',\n",
       " '68',\n",
       " '69',\n",
       " '70',\n",
       " '71',\n",
       " '70',\n",
       " '73',\n",
       " '32',\n",
       " '10',\n",
       " '26',\n",
       " '31',\n",
       " '62',\n",
       " '79',\n",
       " '80',\n",
       " '69',\n",
       " '11',\n",
       " '77',\n",
       " '29',\n",
       " '65',\n",
       " '78',\n",
       " '38',\n",
       " '33',\n",
       " '75',\n",
       " '68',\n",
       " '87',\n",
       " '64',\n",
       " '67',\n",
       " '11',\n",
       " '1',\n",
       " '93',\n",
       " '73',\n",
       " '79',\n",
       " '99',\n",
       " '12']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "#fetching the weeks on board\n",
    "try:\n",
    "    weeks=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--week']\")\n",
    "    for i in weeks:\n",
    "        wob.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    wob.append('No details available')\n",
    "\n",
    "except StaleElementReferenceException:#handling Stale element exception\n",
    "    wob.append('No details available')\n",
    "\n",
    "print(len(wob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3',\n",
       " '4',\n",
       " '36',\n",
       " '12',\n",
       " '14',\n",
       " '26',\n",
       " '9',\n",
       " '17',\n",
       " '10',\n",
       " '1',\n",
       " '11',\n",
       " '27',\n",
       " '33',\n",
       " '9',\n",
       " '79',\n",
       " '1',\n",
       " '22',\n",
       " '14',\n",
       " '3',\n",
       " '1',\n",
       " '2',\n",
       " '22',\n",
       " '17',\n",
       " '21',\n",
       " '17',\n",
       " '3',\n",
       " '1',\n",
       " '3',\n",
       " '18',\n",
       " '44',\n",
       " '1',\n",
       " '6',\n",
       " '16',\n",
       " '1',\n",
       " '3',\n",
       " '7',\n",
       " '14',\n",
       " '11',\n",
       " '14',\n",
       " '13',\n",
       " '21',\n",
       " '43',\n",
       " '1',\n",
       " '16',\n",
       " '40',\n",
       " '1',\n",
       " '4',\n",
       " '23',\n",
       " '18',\n",
       " '12',\n",
       " '7',\n",
       " '15',\n",
       " '2',\n",
       " '3',\n",
       " '13',\n",
       " '1',\n",
       " '3',\n",
       " '1',\n",
       " '20',\n",
       " '1',\n",
       " '4',\n",
       " '15',\n",
       " '18',\n",
       " '4',\n",
       " '3',\n",
       " '8',\n",
       " '1',\n",
       " '1',\n",
       " '3',\n",
       " '1',\n",
       " '1',\n",
       " '6',\n",
       " '1',\n",
       " '16',\n",
       " '6',\n",
       " '18',\n",
       " '17',\n",
       " '26',\n",
       " '1',\n",
       " '1',\n",
       " '5',\n",
       " '5',\n",
       " '7',\n",
       " '3',\n",
       " '18',\n",
       " '9',\n",
       " '4',\n",
       " '3',\n",
       " '2',\n",
       " '10',\n",
       " '7',\n",
       " '2',\n",
       " '10',\n",
       " '12',\n",
       " '14',\n",
       " '4',\n",
       " '6',\n",
       " '7',\n",
       " '1',\n",
       " '4']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape the details of Data science recruiters from naukri.com.\n",
    "#Url = https://www.naukri.com/\n",
    "#We have to find the following details:\n",
    "#A) Name\n",
    "#B) Designation\n",
    "#C) Company\n",
    "#D) Skills they hire for\n",
    "#E) Location\n",
    "\n",
    "#Lets first connect to the webdriver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the url\n",
    "url='https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Locating the search_button to click the word 'recruiters'\n",
    "search_button=driver.find_elements_by_xpath(\"//div[@class='mTxt']\")[1].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining variables\n",
    "name=[]\n",
    "designation=[]\n",
    "company=[]\n",
    "skill=[]\n",
    "location=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#fetching the names of the recruiters\n",
    "try:\n",
    "    names=driver.find_elements_by_xpath(\"//div[@class='recInfo']/div/p/a[1]\")\n",
    "    for i in names:\n",
    "        name.append(i.text)\n",
    "        \n",
    "except NoSuchElementException:    #handling no such element exception\n",
    "    name.append('No details available')\n",
    "    \n",
    "print(len(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape the details of Highest selling novels.\n",
    "#Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\n",
    "#We have to find the following details:\n",
    "#A) Book name\n",
    "#B) Author name\n",
    "#C) Volumes sold\n",
    "#D) Publisher\n",
    "#E) Genre\n",
    "\n",
    "#Lets first connect to the webdriver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the url\n",
    "url='https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining variables\n",
    "detail=[] #book name,author name,volume sales,publisher\n",
    "genre_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "#fetching the book names,author names,volume sales and publisher\n",
    "try:\n",
    "    details=driver.find_elements_by_xpath(\"//td[@class='left']\")\n",
    "    for i in details:\n",
    "        detail.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    detail.append('No details available')\n",
    "\n",
    "except StaleElementReferenceException:#handling Stale element exception\n",
    "    detail.append('No details available')\n",
    "\n",
    "print(len(detail))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " 'Da Vinci Code,The',\n",
       " 'Brown, Dan',\n",
       " '5,094,805',\n",
       " 'Transworld',\n",
       " '2',\n",
       " 'Harry Potter and the Deathly Hallows',\n",
       " 'Rowling, J.K.',\n",
       " '4,475,152',\n",
       " 'Bloomsbury',\n",
       " '3',\n",
       " \"Harry Potter and the Philosopher's Stone\",\n",
       " 'Rowling, J.K.',\n",
       " '4,200,654',\n",
       " 'Bloomsbury',\n",
       " '4',\n",
       " 'Harry Potter and the Order of the Phoenix',\n",
       " 'Rowling, J.K.',\n",
       " '4,179,479',\n",
       " 'Bloomsbury',\n",
       " '5',\n",
       " 'Fifty Shades of Grey',\n",
       " 'James, E. L.',\n",
       " '3,758,936',\n",
       " 'Random House',\n",
       " '6',\n",
       " 'Harry Potter and the Goblet of Fire',\n",
       " 'Rowling, J.K.',\n",
       " '3,583,215',\n",
       " 'Bloomsbury',\n",
       " '7',\n",
       " 'Harry Potter and the Chamber of Secrets',\n",
       " 'Rowling, J.K.',\n",
       " '3,484,047',\n",
       " 'Bloomsbury',\n",
       " '8',\n",
       " 'Harry Potter and the Prisoner of Azkaban',\n",
       " 'Rowling, J.K.',\n",
       " '3,377,906',\n",
       " 'Bloomsbury',\n",
       " '9',\n",
       " 'Angels and Demons',\n",
       " 'Brown, Dan',\n",
       " '3,193,946',\n",
       " 'Transworld',\n",
       " '10',\n",
       " \"Harry Potter and the Half-blood Prince:Children's Edition\",\n",
       " 'Rowling, J.K.',\n",
       " '2,950,264',\n",
       " 'Bloomsbury',\n",
       " '11',\n",
       " 'Fifty Shades Darker',\n",
       " 'James, E. L.',\n",
       " '2,479,784',\n",
       " 'Random House',\n",
       " '12',\n",
       " 'Twilight',\n",
       " 'Meyer, Stephenie',\n",
       " '2,315,405',\n",
       " 'Little, Brown Book',\n",
       " '13',\n",
       " 'Girl with the Dragon Tattoo,The:Millennium Trilogy',\n",
       " 'Larsson, Stieg',\n",
       " '2,233,570',\n",
       " 'Quercus',\n",
       " '14',\n",
       " 'Fifty Shades Freed',\n",
       " 'James, E. L.',\n",
       " '2,193,928',\n",
       " 'Random House',\n",
       " '15',\n",
       " 'Lost Symbol,The',\n",
       " 'Brown, Dan',\n",
       " '2,183,031',\n",
       " 'Transworld',\n",
       " '16',\n",
       " 'New Moon',\n",
       " 'Meyer, Stephenie',\n",
       " '2,152,737',\n",
       " 'Little, Brown Book',\n",
       " '17',\n",
       " 'Deception Point',\n",
       " 'Brown, Dan',\n",
       " '2,062,145',\n",
       " 'Transworld',\n",
       " '18',\n",
       " 'Eclipse',\n",
       " 'Meyer, Stephenie',\n",
       " '2,052,876',\n",
       " 'Little, Brown Book',\n",
       " '19',\n",
       " 'Lovely Bones,The',\n",
       " 'Sebold, Alice',\n",
       " '2,005,598',\n",
       " 'Pan Macmillan',\n",
       " '20',\n",
       " 'Curious Incident of the Dog in the Night-time,The',\n",
       " 'Haddon, Mark',\n",
       " '1,979,552',\n",
       " 'Random House',\n",
       " '21',\n",
       " 'Digital Fortress',\n",
       " 'Brown, Dan',\n",
       " '1,928,900',\n",
       " 'Transworld',\n",
       " '22',\n",
       " 'Short History of Nearly Everything,A',\n",
       " 'Bryson, Bill',\n",
       " '1,852,919',\n",
       " 'Transworld',\n",
       " '23',\n",
       " 'Girl Who Played with Fire,The:Millennium Trilogy',\n",
       " 'Larsson, Stieg',\n",
       " '1,814,784',\n",
       " 'Quercus',\n",
       " '24',\n",
       " 'Breaking Dawn',\n",
       " 'Meyer, Stephenie',\n",
       " '1,787,118',\n",
       " 'Little, Brown Book',\n",
       " '25',\n",
       " 'Very Hungry Caterpillar,The:The Very Hungry Caterpillar',\n",
       " 'Carle, Eric',\n",
       " '1,783,535',\n",
       " 'Penguin',\n",
       " '26',\n",
       " 'Gruffalo,The',\n",
       " 'Donaldson, Julia',\n",
       " '1,781,269',\n",
       " 'Pan Macmillan',\n",
       " '27',\n",
       " \"Jamie's 30-Minute Meals\",\n",
       " 'Oliver, Jamie',\n",
       " '1,743,266',\n",
       " 'Penguin',\n",
       " '28',\n",
       " 'Kite Runner,The',\n",
       " 'Hosseini, Khaled',\n",
       " '1,629,119',\n",
       " 'Bloomsbury',\n",
       " '29',\n",
       " 'One Day',\n",
       " 'Nicholls, David',\n",
       " '1,616,068',\n",
       " 'Hodder & Stoughton',\n",
       " '30',\n",
       " 'Thousand Splendid Suns,A',\n",
       " 'Hosseini, Khaled',\n",
       " '1,583,992',\n",
       " 'Bloomsbury',\n",
       " '31',\n",
       " \"Girl Who Kicked the Hornets' Nest,The:Millennium Trilogy\",\n",
       " 'Larsson, Stieg',\n",
       " '1,555,135',\n",
       " 'Quercus',\n",
       " '32',\n",
       " \"Time Traveler's Wife,The\",\n",
       " 'Niffenegger, Audrey',\n",
       " '1,546,886',\n",
       " 'Random House',\n",
       " '33',\n",
       " 'Atonement',\n",
       " 'McEwan, Ian',\n",
       " '1,539,428',\n",
       " 'Random House',\n",
       " '34',\n",
       " \"Bridget Jones's Diary:A Novel\",\n",
       " 'Fielding, Helen',\n",
       " '1,508,205',\n",
       " 'Pan Macmillan',\n",
       " '35',\n",
       " 'World According to Clarkson,The',\n",
       " 'Clarkson, Jeremy',\n",
       " '1,489,403',\n",
       " 'Penguin',\n",
       " '36',\n",
       " \"Captain Corelli's Mandolin\",\n",
       " 'Bernieres, Louis de',\n",
       " '1,352,318',\n",
       " 'Random House',\n",
       " '37',\n",
       " 'Sound of Laughter,The',\n",
       " 'Kay, Peter',\n",
       " '1,310,207',\n",
       " 'Random House',\n",
       " '38',\n",
       " 'Life of Pi',\n",
       " 'Martel, Yann',\n",
       " '1,310,176',\n",
       " 'Canongate',\n",
       " '39',\n",
       " 'Billy Connolly',\n",
       " 'Stephenson, Pamela',\n",
       " '1,231,957',\n",
       " 'HarperCollins',\n",
       " '40',\n",
       " 'Child Called It,A',\n",
       " 'Pelzer, Dave',\n",
       " '1,217,712',\n",
       " 'Orion',\n",
       " '41',\n",
       " \"Gruffalo's Child,The\",\n",
       " 'Donaldson, Julia',\n",
       " '1,208,711',\n",
       " 'Pan Macmillan',\n",
       " '42',\n",
       " \"Angela's Ashes:A Memoir of a Childhood\",\n",
       " 'McCourt, Frank',\n",
       " '1,204,058',\n",
       " 'HarperCollins',\n",
       " '43',\n",
       " 'Birdsong',\n",
       " 'Faulks, Sebastian',\n",
       " '1,184,967',\n",
       " 'Random House',\n",
       " '44',\n",
       " 'Northern Lights:His Dark Materials S.',\n",
       " 'Pullman, Philip',\n",
       " '1,181,503',\n",
       " 'Scholastic Ltd.',\n",
       " '45',\n",
       " 'Labyrinth',\n",
       " 'Mosse, Kate',\n",
       " '1,181,093',\n",
       " 'Orion',\n",
       " '46',\n",
       " 'Harry Potter and the Half-blood Prince',\n",
       " 'Rowling, J.K.',\n",
       " '1,153,181',\n",
       " 'Bloomsbury',\n",
       " '47',\n",
       " 'Help,The',\n",
       " 'Stockett, Kathryn',\n",
       " '1,132,336',\n",
       " 'Penguin',\n",
       " '48',\n",
       " 'Man and Boy',\n",
       " 'Parsons, Tony',\n",
       " '1,130,802',\n",
       " 'HarperCollins',\n",
       " '49',\n",
       " 'Memoirs of a Geisha',\n",
       " 'Golden, Arthur',\n",
       " '1,126,337',\n",
       " 'Random House',\n",
       " '50',\n",
       " \"No.1 Ladies' Detective Agency,The:No.1 Ladies' Detective Agency S.\",\n",
       " 'McCall Smith, Alexander',\n",
       " '1,115,549',\n",
       " 'Little, Brown Book',\n",
       " '51',\n",
       " 'Island,The',\n",
       " 'Hislop, Victoria',\n",
       " '1,108,328',\n",
       " 'Headline',\n",
       " '52',\n",
       " 'PS, I Love You',\n",
       " 'Ahern, Cecelia',\n",
       " '1,107,379',\n",
       " 'HarperCollins',\n",
       " '53',\n",
       " 'You are What You Eat:The Plan That Will Change Your Life',\n",
       " 'McKeith, Gillian',\n",
       " '1,104,403',\n",
       " 'Penguin',\n",
       " '54',\n",
       " 'Shadow of the Wind,The',\n",
       " 'Zafon, Carlos Ruiz',\n",
       " '1,092,349',\n",
       " 'Orion',\n",
       " '55',\n",
       " 'Tales of Beedle the Bard,The',\n",
       " 'Rowling, J.K.',\n",
       " '1,090,847',\n",
       " 'Bloomsbury',\n",
       " '56',\n",
       " 'Broker,The',\n",
       " 'Grisham, John',\n",
       " '1,087,262',\n",
       " 'Random House',\n",
       " '57',\n",
       " \"Dr. Atkins' New Diet Revolution:The No-hunger, Luxurious Weight Loss P\",\n",
       " 'Atkins, Robert C.',\n",
       " '1,054,196',\n",
       " 'Random House',\n",
       " '58',\n",
       " 'Subtle Knife,The:His Dark Materials S.',\n",
       " 'Pullman, Philip',\n",
       " '1,037,160',\n",
       " 'Scholastic Ltd.',\n",
       " '59',\n",
       " 'Eats, Shoots and Leaves:The Zero Tolerance Approach to Punctuation',\n",
       " 'Truss, Lynne',\n",
       " '1,023,688',\n",
       " 'Profile Books Group',\n",
       " '60',\n",
       " \"Delia's How to Cook:(Bk.1)\",\n",
       " 'Smith, Delia',\n",
       " '1,015,956',\n",
       " 'Random House',\n",
       " '61',\n",
       " 'Chocolat',\n",
       " 'Harris, Joanne',\n",
       " '1,009,873',\n",
       " 'Transworld',\n",
       " '62',\n",
       " 'Boy in the Striped Pyjamas,The',\n",
       " 'Boyne, John',\n",
       " '1,004,414',\n",
       " 'Random House Childrens Books G',\n",
       " '63',\n",
       " \"My Sister's Keeper\",\n",
       " 'Picoult, Jodi',\n",
       " '1,003,780',\n",
       " 'Hodder & Stoughton',\n",
       " '64',\n",
       " 'Amber Spyglass,The:His Dark Materials S.',\n",
       " 'Pullman, Philip',\n",
       " '1,002,314',\n",
       " 'Scholastic Ltd.',\n",
       " '65',\n",
       " 'To Kill a Mockingbird',\n",
       " 'Lee, Harper',\n",
       " '998,213',\n",
       " 'Random House',\n",
       " '66',\n",
       " 'Men are from Mars, Women are from Venus:A Practical Guide for Improvin',\n",
       " 'Gray, John',\n",
       " '992,846',\n",
       " 'HarperCollins',\n",
       " '67',\n",
       " 'Dear Fatty',\n",
       " 'French, Dawn',\n",
       " '986,753',\n",
       " 'Random House',\n",
       " '68',\n",
       " 'Short History of Tractors in Ukrainian,A',\n",
       " 'Lewycka, Marina',\n",
       " '986,115',\n",
       " 'Penguin',\n",
       " '69',\n",
       " 'Hannibal',\n",
       " 'Harris, Thomas',\n",
       " '970,509',\n",
       " 'Random House',\n",
       " '70',\n",
       " 'Lord of the Rings,The',\n",
       " 'Tolkien, J. R. R.',\n",
       " '967,466',\n",
       " 'HarperCollins',\n",
       " '71',\n",
       " 'Stupid White Men:...and Other Sorry Excuses for the State of the Natio',\n",
       " 'Moore, Michael',\n",
       " '963,353',\n",
       " 'Penguin',\n",
       " '72',\n",
       " 'Interpretation of Murder,The',\n",
       " 'Rubenfeld, Jed',\n",
       " '962,515',\n",
       " 'Headline',\n",
       " '73',\n",
       " 'Sharon Osbourne Extreme:My Autobiography',\n",
       " 'Osbourne, Sharon',\n",
       " '959,496',\n",
       " 'Little, Brown Book',\n",
       " '74',\n",
       " 'Alchemist,The:A Fable About Following Your Dream',\n",
       " 'Coelho, Paulo',\n",
       " '956,114',\n",
       " 'HarperCollins',\n",
       " '75',\n",
       " \"At My Mother's Knee ...:and Other Low Joints\",\n",
       " \"O'Grady, Paul\",\n",
       " '945,640',\n",
       " 'Transworld',\n",
       " '76',\n",
       " 'Notes from a Small Island',\n",
       " 'Bryson, Bill',\n",
       " '931,312',\n",
       " 'Transworld',\n",
       " '77',\n",
       " 'Return of the Naked Chef,The',\n",
       " 'Oliver, Jamie',\n",
       " '925,425',\n",
       " 'Penguin',\n",
       " '78',\n",
       " 'Bridget Jones: The Edge of Reason',\n",
       " 'Fielding, Helen',\n",
       " '924,695',\n",
       " 'Pan Macmillan',\n",
       " '79',\n",
       " \"Jamie's Italy\",\n",
       " 'Oliver, Jamie',\n",
       " '906,968',\n",
       " 'Penguin',\n",
       " '80',\n",
       " 'I Can Make You Thin',\n",
       " 'McKenna, Paul',\n",
       " '905,086',\n",
       " 'Transworld',\n",
       " '81',\n",
       " 'Down Under',\n",
       " 'Bryson, Bill',\n",
       " '890,847',\n",
       " 'Transworld',\n",
       " '82',\n",
       " 'Summons,The',\n",
       " 'Grisham, John',\n",
       " '869,671',\n",
       " 'Random House',\n",
       " '83',\n",
       " 'Small Island',\n",
       " 'Levy, Andrea',\n",
       " '869,659',\n",
       " 'Headline',\n",
       " '84',\n",
       " 'Nigella Express',\n",
       " 'Lawson, Nigella',\n",
       " '862,602',\n",
       " 'Random House',\n",
       " '85',\n",
       " 'Brick Lane',\n",
       " 'Ali, Monica',\n",
       " '856,540',\n",
       " 'Transworld',\n",
       " '86',\n",
       " \"Memory Keeper's Daughter,The\",\n",
       " 'Edwards, Kim',\n",
       " '845,858',\n",
       " 'Penguin',\n",
       " '87',\n",
       " 'Room on the Broom',\n",
       " 'Donaldson, Julia',\n",
       " '842,535',\n",
       " 'Pan Macmillan',\n",
       " '88',\n",
       " 'About a Boy',\n",
       " 'Hornby, Nick',\n",
       " '828,215',\n",
       " 'Penguin',\n",
       " '89',\n",
       " 'My Booky Wook',\n",
       " 'Brand, Russell',\n",
       " '820,563',\n",
       " 'Hodder & Stoughton',\n",
       " '90',\n",
       " 'God Delusion,The',\n",
       " 'Dawkins, Richard',\n",
       " '816,907',\n",
       " 'Transworld',\n",
       " '91',\n",
       " '\"Beano\" Annual,The',\n",
       " '0',\n",
       " '816,585',\n",
       " 'D.C. Thomson',\n",
       " '92',\n",
       " 'White Teeth',\n",
       " 'Smith, Zadie',\n",
       " '815,586',\n",
       " 'Penguin',\n",
       " '93',\n",
       " 'House at Riverton,The',\n",
       " 'Morton, Kate',\n",
       " '814,370',\n",
       " 'Pan Macmillan',\n",
       " '94',\n",
       " 'Book Thief,The',\n",
       " 'Zusak, Markus',\n",
       " '809,641',\n",
       " 'Transworld',\n",
       " '95',\n",
       " 'Nights of Rain and Stars',\n",
       " 'Binchy, Maeve',\n",
       " '808,900',\n",
       " 'Orion',\n",
       " '96',\n",
       " 'Ghost,The',\n",
       " 'Harris, Robert',\n",
       " '807,311',\n",
       " 'Random House',\n",
       " '97',\n",
       " 'Happy Days with the Naked Chef',\n",
       " 'Oliver, Jamie',\n",
       " '794,201',\n",
       " 'Penguin',\n",
       " '98',\n",
       " 'Hunger Games,The:Hunger Games Trilogy',\n",
       " 'Collins, Suzanne',\n",
       " '792,187',\n",
       " 'Scholastic Ltd.',\n",
       " '99',\n",
       " \"Lost Boy,The:A Foster Child's Search for the Love of a Family\",\n",
       " 'Pelzer, Dave',\n",
       " '791,507',\n",
       " 'Orion',\n",
       " '100',\n",
       " \"Jamie's Ministry of Food:Anyone Can Learn to Cook in 24 Hours\",\n",
       " 'Oliver, Jamie',\n",
       " '791,095',\n",
       " 'Penguin']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "#fetching the book names,author names,volume sales and publisher\n",
    "try:\n",
    "    genre=driver.find_elements_by_xpath(\"//td[@class='last left']\")\n",
    "    for i in genre:\n",
    "        genre_list.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    genre_list.append('No details available')\n",
    "\n",
    "except StaleElementReferenceException:#handling Stale element exception\n",
    "    genre_list.append('No details available')\n",
    "\n",
    "print(len(genre_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Crime, Thriller & Adventure',\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " 'Romance & Sagas',\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " 'Crime, Thriller & Adventure',\n",
       " \"Children's Fiction\",\n",
       " 'Romance & Sagas',\n",
       " 'Young Adult Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Romance & Sagas',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Popular Science',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'Picture Books',\n",
       " 'Picture Books',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Humour: Collections & General',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Biography: The Arts',\n",
       " 'Autobiography: General',\n",
       " 'Picture Books',\n",
       " 'Autobiography: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Science Fiction & Fantasy',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Fitness & Diet',\n",
       " 'General & Literary Fiction',\n",
       " \"Children's Fiction\",\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Fitness & Diet',\n",
       " 'Young Adult Fiction',\n",
       " 'Usage & Writing Guides',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Popular Culture & Media: General Interest',\n",
       " 'Autobiography: The Arts',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Science Fiction & Fantasy',\n",
       " 'Current Affairs & Issues',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Autobiography: The Arts',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: The Arts',\n",
       " 'Travel Writing',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'National & Regional Cuisine',\n",
       " 'Fitness & Diet',\n",
       " 'Travel Writing',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Picture Books',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: The Arts',\n",
       " 'Popular Science',\n",
       " \"Children's Annuals\",\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Food & Drink: General',\n",
       " 'Young Adult Fiction',\n",
       " 'Biography: General',\n",
       " 'Food & Drink: General']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape the details most watched tv series of all time from imdb.com.\n",
    "#Url = https://www.imdb.com/list/ls095964455/\n",
    "#We have to find the following details:\n",
    "#A) Name\n",
    "#B) Year span\n",
    "#C) Genre\n",
    "#D) Run time\n",
    "#E) Ratings\n",
    "#F) Votes\n",
    "\n",
    "#Lets first connect to the webdriver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the url\n",
    "url='https://www.imdb.com/list/ls095964455/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining variables\n",
    "name_list=[]\n",
    "year_list=[]\n",
    "genre_list=[]\n",
    "runtime_list=[]\n",
    "rating_list=[]\n",
    "vote_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "#fetching the tv series names\n",
    "try:\n",
    "    name=driver.find_elements_by_xpath(\"//h3[@class='lister-item-header']/a\")\n",
    "    for i in name:\n",
    "        name_list.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    name_list.append('No details available')\n",
    "\n",
    "except StaleElementReferenceException:#handling Stale element exception\n",
    "    name_list.append('No details available')\n",
    "\n",
    "print(len(name_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Game of Thrones',\n",
       " 'Stranger Things',\n",
       " 'The Walking Dead',\n",
       " '13 Reasons Why',\n",
       " 'The 100',\n",
       " 'Orange Is the New Black',\n",
       " 'Riverdale',\n",
       " \"Grey's Anatomy\",\n",
       " 'The Flash',\n",
       " 'Arrow',\n",
       " 'Money Heist',\n",
       " 'The Big Bang Theory',\n",
       " 'Black Mirror',\n",
       " 'Sherlock',\n",
       " 'Vikings',\n",
       " 'Pretty Little Liars',\n",
       " 'The Vampire Diaries',\n",
       " 'American Horror Story',\n",
       " 'Breaking Bad',\n",
       " 'Lucifer',\n",
       " 'Supernatural',\n",
       " 'Prison Break',\n",
       " 'How to Get Away with Murder',\n",
       " 'Teen Wolf',\n",
       " 'The Simpsons',\n",
       " 'Once Upon a Time',\n",
       " 'Narcos',\n",
       " 'Daredevil',\n",
       " 'Friends',\n",
       " 'How I Met Your Mother',\n",
       " 'Suits',\n",
       " 'Mr. Robot',\n",
       " 'The Originals',\n",
       " 'Supergirl',\n",
       " 'Gossip Girl',\n",
       " 'Sense8',\n",
       " 'Gotham',\n",
       " 'Westworld',\n",
       " 'Jessica Jones',\n",
       " 'Modern Family',\n",
       " 'Rick and Morty',\n",
       " 'Shadowhunters',\n",
       " 'The End of the F***ing World',\n",
       " 'House of Cards',\n",
       " 'Dark',\n",
       " 'Elite',\n",
       " 'Sex Education',\n",
       " 'Shameless',\n",
       " 'New Girl',\n",
       " 'Agents of S.H.I.E.L.D.',\n",
       " 'You',\n",
       " 'Dexter',\n",
       " 'Fear the Walking Dead',\n",
       " 'Family Guy',\n",
       " 'The Blacklist',\n",
       " 'Lost',\n",
       " 'Peaky Blinders',\n",
       " 'House',\n",
       " 'Quantico',\n",
       " 'Orphan Black',\n",
       " 'Homeland',\n",
       " 'Blindspot',\n",
       " \"DC's Legends of Tomorrow\",\n",
       " \"The Handmaid's Tale\",\n",
       " 'Chilling Adventures of Sabrina',\n",
       " 'The Good Doctor',\n",
       " 'Jane the Virgin',\n",
       " 'Glee',\n",
       " 'South Park',\n",
       " 'Brooklyn Nine-Nine',\n",
       " 'Under the Dome',\n",
       " 'The Umbrella Academy',\n",
       " 'True Detective',\n",
       " 'The OA',\n",
       " 'Desperate Housewives',\n",
       " 'Better Call Saul',\n",
       " 'Bates Motel',\n",
       " 'The Punisher',\n",
       " 'Atypical',\n",
       " 'Dynasty',\n",
       " 'This Is Us',\n",
       " 'The Good Place',\n",
       " 'Iron Fist',\n",
       " 'The Rain',\n",
       " 'Mindhunter',\n",
       " 'Revenge',\n",
       " 'Luke Cage',\n",
       " 'Scandal',\n",
       " 'The Defenders',\n",
       " 'Big Little Lies',\n",
       " 'Insatiable',\n",
       " 'The Mentalist',\n",
       " 'The Crown',\n",
       " 'Chernobyl',\n",
       " 'iZombie',\n",
       " 'Reign',\n",
       " 'A Series of Unfortunate Events',\n",
       " 'Criminal Minds',\n",
       " 'Scream: The TV Series',\n",
       " 'The Haunting of Hill House']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "#fetching the year span\n",
    "try:\n",
    "    year=driver.find_elements_by_xpath(\"//span[@class='lister-item-year text-muted unbold']\")\n",
    "    for i in year:\n",
    "        year_list.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    year_list.append('No details available')\n",
    "\n",
    "except StaleElementReferenceException:#handling Stale element exception\n",
    "    year_list.append('No details available')\n",
    "\n",
    "print(len(year_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(2011–2019)',\n",
       " '(2016– )',\n",
       " '(2010–2022)',\n",
       " '(2017–2020)',\n",
       " '(2014–2020)',\n",
       " '(2013–2019)',\n",
       " '(2017– )',\n",
       " '(2005– )',\n",
       " '(2014– )',\n",
       " '(2012–2020)',\n",
       " '(2017–2021)',\n",
       " '(2007–2019)',\n",
       " '(2011– )',\n",
       " '(2010–2017)',\n",
       " '(2013–2020)',\n",
       " '(2010–2017)',\n",
       " '(2009–2017)',\n",
       " '(2011– )',\n",
       " '(2008–2013)',\n",
       " '(2016– )',\n",
       " '(2005–2020)',\n",
       " '(2005–2017)',\n",
       " '(2014–2020)',\n",
       " '(2011–2017)',\n",
       " '(1989– )',\n",
       " '(2011–2018)',\n",
       " '(2015–2017)',\n",
       " '(2015–2018)',\n",
       " '(1994–2004)',\n",
       " '(2005–2014)',\n",
       " '(2011–2019)',\n",
       " '(2015–2019)',\n",
       " '(2013–2018)',\n",
       " '(2015–2021)',\n",
       " '(2007–2012)',\n",
       " '(2015–2018)',\n",
       " '(2014–2019)',\n",
       " '(2016– )',\n",
       " '(2015–2019)',\n",
       " '(2009–2020)',\n",
       " '(2013– )',\n",
       " '(2016–2019)',\n",
       " '(2017–2019)',\n",
       " '(2013–2018)',\n",
       " '(2017–2020)',\n",
       " '(2018– )',\n",
       " '(2019– )',\n",
       " '(2011–2021)',\n",
       " '(2011–2018)',\n",
       " '(2013–2020)',\n",
       " '(2018– )',\n",
       " '(2006–2021)',\n",
       " '(2015– )',\n",
       " '(1999– )',\n",
       " '(2013– )',\n",
       " '(2004–2010)',\n",
       " '(2013– )',\n",
       " '(2004–2012)',\n",
       " '(2015–2018)',\n",
       " '(2013–2017)',\n",
       " '(2011–2020)',\n",
       " '(2015–2020)',\n",
       " '(2016– )',\n",
       " '(2017– )',\n",
       " '(2018–2020)',\n",
       " '(2017– )',\n",
       " '(2014–2019)',\n",
       " '(2009–2015)',\n",
       " '(1997– )',\n",
       " '(2013–2022)',\n",
       " '(2013–2015)',\n",
       " '(2019– )',\n",
       " '(2014–2019)',\n",
       " '(2016–2019)',\n",
       " '(2004–2012)',\n",
       " '(2015– )',\n",
       " '(2013–2017)',\n",
       " '(2017–2019)',\n",
       " '(2017–2021)',\n",
       " '(2017– )',\n",
       " '(2016–2022)',\n",
       " '(2016–2020)',\n",
       " '(2017–2018)',\n",
       " '(2018–2020)',\n",
       " '(2017–2019)',\n",
       " '(2011–2015)',\n",
       " '(2016–2018)',\n",
       " '(2012–2018)',\n",
       " '(2017)',\n",
       " '(2017–2019)',\n",
       " '(2018–2019)',\n",
       " '(2008–2015)',\n",
       " '(2016– )',\n",
       " '(2019)',\n",
       " '(2015–2019)',\n",
       " '(2013–2017)',\n",
       " '(2017–2019)',\n",
       " '(2005–2020)',\n",
       " '(2015–2019)',\n",
       " '(2018)']"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "#fetching the genre list\n",
    "try:\n",
    "    genre=driver.find_elements_by_xpath(\"//span[@class='genre']\")\n",
    "    for i in genre:\n",
    "        genre_list.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    genre_list.append('No details available')\n",
    "\n",
    "except StaleElementReferenceException:#handling Stale element exception\n",
    "    genre_list.append('No details available')\n",
    "\n",
    "print(len(genre_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Action, Adventure, Drama',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama, Horror, Thriller',\n",
       " 'Drama, Mystery, Thriller',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Romance',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Action, Crime, Mystery',\n",
       " 'Comedy, Romance',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Mystery, Romance',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama, Horror, Thriller',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Crime, Drama, Fantasy',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Action, Crime, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Animation, Comedy',\n",
       " 'Adventure, Fantasy, Romance',\n",
       " 'Biography, Crime, Drama',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Comedy, Romance',\n",
       " 'Comedy, Drama',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Romance',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Crime, Drama',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Animation, Adventure, Comedy',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Adventure, Comedy, Crime',\n",
       " 'Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Comedy, Drama',\n",
       " 'Comedy, Drama',\n",
       " 'Comedy',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Crime, Drama, Romance',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Horror, Sci-Fi',\n",
       " 'Animation, Comedy',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Adventure, Drama, Fantasy',\n",
       " 'Crime, Drama',\n",
       " 'Drama, Mystery',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Drama, Sci-Fi',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Crime, Drama',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama',\n",
       " 'Comedy',\n",
       " 'Comedy, Drama, Music',\n",
       " 'Animation, Comedy',\n",
       " 'Comedy, Crime',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Adventure, Comedy',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Fantasy, Mystery',\n",
       " 'Comedy, Drama, Mystery',\n",
       " 'Crime, Drama',\n",
       " 'Drama, Horror, Mystery',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Drama',\n",
       " 'Drama',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Comedy, Drama, Fantasy',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Drama, Mystery, Thriller',\n",
       " 'Action, Crime, Drama',\n",
       " 'Drama, Thriller',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Comedy, Drama, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Biography, Drama, History',\n",
       " 'Drama, History, Thriller',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Drama, Fantasy',\n",
       " 'Adventure, Comedy, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Drama, Horror, Mystery']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "#fetching the run time list\n",
    "try:\n",
    "    time=driver.find_elements_by_xpath(\"//span[@class='runtime']\")\n",
    "    for i in time:\n",
    "        runtime_list.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    runtime_list.append('No details available')\n",
    "\n",
    "except StaleElementReferenceException:#handling Stale element exception\n",
    "    runtime_list.append('No details available')\n",
    "\n",
    "print(len(runtime_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['57 min',\n",
       " '51 min',\n",
       " '44 min',\n",
       " '60 min',\n",
       " '43 min',\n",
       " '59 min',\n",
       " '45 min',\n",
       " '41 min',\n",
       " '43 min',\n",
       " '42 min',\n",
       " '70 min',\n",
       " '22 min',\n",
       " '60 min',\n",
       " '88 min',\n",
       " '44 min',\n",
       " '44 min',\n",
       " '43 min',\n",
       " '60 min',\n",
       " '49 min',\n",
       " '42 min',\n",
       " '44 min',\n",
       " '44 min',\n",
       " '43 min',\n",
       " '41 min',\n",
       " '22 min',\n",
       " '60 min',\n",
       " '49 min',\n",
       " '54 min',\n",
       " '22 min',\n",
       " '22 min',\n",
       " '44 min',\n",
       " '49 min',\n",
       " '45 min',\n",
       " '43 min',\n",
       " '42 min',\n",
       " '60 min',\n",
       " '42 min',\n",
       " '62 min',\n",
       " '56 min',\n",
       " '22 min',\n",
       " '23 min',\n",
       " '42 min',\n",
       " '25 min',\n",
       " '51 min',\n",
       " '60 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '46 min',\n",
       " '22 min',\n",
       " '45 min',\n",
       " '45 min',\n",
       " '53 min',\n",
       " '44 min',\n",
       " '22 min',\n",
       " '43 min',\n",
       " '44 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '42 min',\n",
       " '44 min',\n",
       " '55 min',\n",
       " '42 min',\n",
       " '42 min',\n",
       " '60 min',\n",
       " '60 min',\n",
       " '41 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '22 min',\n",
       " '22 min',\n",
       " '43 min',\n",
       " '60 min',\n",
       " '55 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '46 min',\n",
       " '45 min',\n",
       " '53 min',\n",
       " '30 min',\n",
       " '42 min',\n",
       " '45 min',\n",
       " '22 min',\n",
       " '55 min',\n",
       " '45 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '55 min',\n",
       " '43 min',\n",
       " '50 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '43 min',\n",
       " '58 min',\n",
       " '330 min',\n",
       " '42 min',\n",
       " '42 min',\n",
       " '50 min',\n",
       " '42 min',\n",
       " '45 min',\n",
       " '572 min']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runtime_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2300\n"
     ]
    }
   ],
   "source": [
    "#fetching the ratings list\n",
    "try:\n",
    "    rating=driver.find_elements_by_xpath(\"//span[@class='ipl-rating-star__rating']\")\n",
    "    for i in rating:\n",
    "        rating_list.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    rating_list.append('No details available')\n",
    "\n",
    "except StaleElementReferenceException:#handling Stale element exception\n",
    "    rating_list.append('No details available')\n",
    "\n",
    "print(len(rating_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9.3',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '8.7',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '8.2',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '7.6',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '7.6',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '8',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '6.8',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '7.5',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '7.6',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '7.5',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '8.3',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '8.1',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '8.8',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '9.1',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '8.5',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '7.4',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '7.7',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '8',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '9.4',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '8.1',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '8.4',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '8.3',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '8.1',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '7.6',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '8.6',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '7.7',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '8.8',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '8.6',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '8.9',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '8.3',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '8.4',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '8.5',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '8.2',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '6.2',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '7.4',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '8.3',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '7.8',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '8.6',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '7.9',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '8.4',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '9.2',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '6.6',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '8.1',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '8.7',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " ...]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "#fetching the vote list\n",
    "try:\n",
    "    votes=driver.find_elements_by_name(\"nv\")\n",
    "    for i in votes:\n",
    "        vote_list.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    vote_list.append('No details available')\n",
    "\n",
    "except StaleElementReferenceException:#handling Stale element exception\n",
    "    vote_list.append('No details available')\n",
    "\n",
    "print(len(vote_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,824,559',\n",
       " '864,714',\n",
       " '874,933',\n",
       " '262,835',\n",
       " '224,227',\n",
       " '282,747',\n",
       " '125,138',\n",
       " '261,464',\n",
       " '314,648',\n",
       " '412,432',\n",
       " '331,743',\n",
       " '737,560',\n",
       " '462,728',\n",
       " '830,557',\n",
       " '451,846',\n",
       " '154,747',\n",
       " '290,578',\n",
       " '282,607',\n",
       " '1,527,514',\n",
       " '253,193',\n",
       " '400,060',\n",
       " '487,817',\n",
       " '134,313',\n",
       " '131,154',\n",
       " '372,567',\n",
       " '211,292',\n",
       " '370,896',\n",
       " '371,168',\n",
       " '864,673',\n",
       " '618,259',\n",
       " '371,380',\n",
       " '342,328',\n",
       " '121,178',\n",
       " '114,331',\n",
       " '157,750',\n",
       " '142,830',\n",
       " '214,949',\n",
       " '439,937',\n",
       " '196,443',\n",
       " '371,249',\n",
       " '395,496',\n",
       " '55,418',\n",
       " '154,467',\n",
       " '473,787',\n",
       " '305,542',\n",
       " '53,891',\n",
       " '171,461',\n",
       " '211,126',\n",
       " '198,113',\n",
       " '203,613',\n",
       " '153,810',\n",
       " '658,619',\n",
       " '116,530',\n",
       " '310,167',\n",
       " '207,923',\n",
       " '507,281',\n",
       " '380,686',\n",
       " '422,673',\n",
       " '57,859',\n",
       " '103,469',\n",
       " '320,279',\n",
       " '67,643',\n",
       " '94,493',\n",
       " '187,351',\n",
       " '81,303',\n",
       " '67,743',\n",
       " '40,686',\n",
       " '138,863',\n",
       " '337,474',\n",
       " '242,569',\n",
       " '102,164',\n",
       " '171,070',\n",
       " '510,886',\n",
       " '93,601',\n",
       " '118,606',\n",
       " '341,333',\n",
       " '99,229',\n",
       " '191,616',\n",
       " '64,364',\n",
       " '16,133',\n",
       " '114,570',\n",
       " '123,985',\n",
       " '117,537',\n",
       " '32,325',\n",
       " '230,521',\n",
       " '114,149',\n",
       " '119,127',\n",
       " '68,232',\n",
       " '93,456',\n",
       " '164,891',\n",
       " '23,652',\n",
       " '168,810',\n",
       " '166,262',\n",
       " '582,458',\n",
       " '61,636',\n",
       " '44,595',\n",
       " '55,100',\n",
       " '167,934',\n",
       " '34,911',\n",
       " '191,620']"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape details of Datasets from UCI machine learning repositories.\n",
    "#Url = https://archive.ics.uci.edu/\n",
    "#We have to find the following details:\n",
    "#A) Dataset name\n",
    "#B) Data type\n",
    "#C) Task\n",
    "#D) Attribute type\n",
    "#E) No of instances\n",
    "#F) No of attribute\n",
    "#G) Year\n",
    "\n",
    "#Lets first connect to the webdriver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the url\n",
    "url='https://archive.ics.uci.edu/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Locating the search_button to click the word 'View All Data Sets'\n",
    "search_button=driver.find_elements_by_xpath(\"//span[@class='whitetext']/a\")[4].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining variables\n",
    "name=[]\n",
    "data=[]\n",
    "task=[]\n",
    "attribute=[]\n",
    "instancesno=[]\n",
    "attributeno=[]\n",
    "year=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "588\n"
     ]
    }
   ],
   "source": [
    "#fetching the dataset name\n",
    "try:\n",
    "    dataset=driver.find_elements_by_xpath(\"//p[@class='normal']/b/a\")\n",
    "    for i in dataset:\n",
    "        name.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    name.append('No details available')\n",
    "\n",
    "print(len(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abalone',\n",
       " 'Adult',\n",
       " 'Annealing',\n",
       " 'Anonymous Microsoft Web Data',\n",
       " 'Arrhythmia',\n",
       " 'Artificial Characters',\n",
       " 'Audiology (Original)',\n",
       " 'Audiology (Standardized)',\n",
       " 'Auto MPG',\n",
       " 'Automobile',\n",
       " 'Badges',\n",
       " 'Balance Scale',\n",
       " 'Balloons',\n",
       " 'Breast Cancer',\n",
       " 'Breast Cancer Wisconsin (Original)',\n",
       " 'Breast Cancer Wisconsin (Prognostic)',\n",
       " 'Breast Cancer Wisconsin (Diagnostic)',\n",
       " 'Pittsburgh Bridges',\n",
       " 'Car Evaluation',\n",
       " 'Census Income',\n",
       " 'Chess (King-Rook vs. King-Knight)',\n",
       " 'Chess (King-Rook vs. King-Pawn)',\n",
       " 'Chess (King-Rook vs. King)',\n",
       " 'Chess (Domain Theories)',\n",
       " 'Bach Chorales',\n",
       " 'Connect-4',\n",
       " 'Credit Approval',\n",
       " 'Japanese Credit Screening',\n",
       " 'Computer Hardware',\n",
       " 'Contraceptive Method Choice',\n",
       " 'Covertype',\n",
       " 'Cylinder Bands',\n",
       " 'Dermatology',\n",
       " 'Diabetes',\n",
       " 'DGP2 - The Second Data Generation Program',\n",
       " 'Document Understanding',\n",
       " 'EBL Domain Theories',\n",
       " 'Echocardiogram',\n",
       " 'Ecoli',\n",
       " 'Flags',\n",
       " 'Function Finding',\n",
       " 'Glass Identification',\n",
       " \"Haberman's Survival\",\n",
       " 'Hayes-Roth',\n",
       " 'Heart Disease',\n",
       " 'Hepatitis',\n",
       " 'Horse Colic',\n",
       " 'ICU',\n",
       " 'Image Segmentation',\n",
       " 'Internet Advertisements',\n",
       " 'Ionosphere',\n",
       " 'Iris',\n",
       " 'ISOLET',\n",
       " 'Kinship',\n",
       " 'Labor Relations',\n",
       " 'LED Display Domain',\n",
       " 'Lenses',\n",
       " 'Letter Recognition',\n",
       " 'Liver Disorders',\n",
       " 'Logic Theorist',\n",
       " 'Lung Cancer',\n",
       " 'Lymphography',\n",
       " 'Mechanical Analysis',\n",
       " 'Meta-data',\n",
       " 'Mobile Robots',\n",
       " 'Molecular Biology (Promoter Gene Sequences)',\n",
       " 'Molecular Biology (Protein Secondary Structure)',\n",
       " 'Molecular Biology (Splice-junction Gene Sequences)',\n",
       " \"MONK's Problems\",\n",
       " 'Moral Reasoner',\n",
       " 'Multiple Features',\n",
       " 'Mushroom',\n",
       " 'Musk (Version 1)',\n",
       " 'Musk (Version 2)',\n",
       " 'Nursery',\n",
       " 'Othello Domain Theory',\n",
       " 'Page Blocks Classification',\n",
       " 'Optical Recognition of Handwritten Digits',\n",
       " 'Pen-Based Recognition of Handwritten Digits',\n",
       " 'Post-Operative Patient',\n",
       " 'Primary Tumor',\n",
       " 'Prodigy',\n",
       " 'Qualitative Structure Activity Relationships',\n",
       " 'Quadruped Mammals',\n",
       " 'Servo',\n",
       " 'Shuttle Landing Control',\n",
       " 'Solar Flare',\n",
       " 'Soybean (Large)',\n",
       " 'Soybean (Small)',\n",
       " 'Challenger USA Space Shuttle O-Ring',\n",
       " 'Low Resolution Spectrometer',\n",
       " 'Spambase',\n",
       " 'SPECT Heart',\n",
       " 'SPECTF Heart',\n",
       " 'Sponge',\n",
       " 'Statlog Project',\n",
       " 'Student Loan Relational',\n",
       " 'Teaching Assistant Evaluation',\n",
       " 'Tic-Tac-Toe Endgame',\n",
       " 'Thyroid Disease',\n",
       " 'Trains',\n",
       " 'University',\n",
       " 'Congressional Voting Records',\n",
       " 'Water Treatment Plant',\n",
       " 'Waveform Database Generator (Version 1)',\n",
       " 'Waveform Database Generator (Version 2)',\n",
       " 'Wine',\n",
       " 'Yeast',\n",
       " 'Zoo',\n",
       " 'Undocumented',\n",
       " 'Twenty Newsgroups',\n",
       " 'Australian Sign Language signs',\n",
       " 'Australian Sign Language signs (High Quality)',\n",
       " 'US Census Data (1990)',\n",
       " 'Census-Income (KDD)',\n",
       " 'Coil 1999 Competition Data',\n",
       " 'Corel Image Features',\n",
       " 'E. Coli Genes',\n",
       " 'EEG Database',\n",
       " 'El Nino',\n",
       " 'Entree Chicago Recommendation Data',\n",
       " 'CMU Face Images',\n",
       " 'Insurance Company Benchmark (COIL 2000)',\n",
       " 'Internet Usage Data',\n",
       " 'IPUMS Census Database',\n",
       " 'Japanese Vowels',\n",
       " 'KDD Cup 1998 Data',\n",
       " 'KDD Cup 1999 Data',\n",
       " 'M. Tuberculosis Genes',\n",
       " 'Movie',\n",
       " 'MSNBC.com Anonymous Web Data',\n",
       " 'NSF Research Award Abstracts 1990-2003',\n",
       " 'Pioneer-1 Mobile Robot Data',\n",
       " 'Pseudo Periodic Synthetic Time Series',\n",
       " 'Reuters-21578 Text Categorization Collection',\n",
       " 'Robot Execution Failures',\n",
       " 'Synthetic Control Chart Time Series',\n",
       " 'Syskill and Webert Web Page Ratings',\n",
       " 'UNIX User Data',\n",
       " 'Volcanoes on Venus - JARtool experiment',\n",
       " 'Statlog (Australian Credit Approval)',\n",
       " 'Statlog (German Credit Data)',\n",
       " 'Statlog (Heart)',\n",
       " 'Statlog (Landsat Satellite)',\n",
       " 'Statlog (Image Segmentation)',\n",
       " 'Statlog (Shuttle)',\n",
       " 'Statlog (Vehicle Silhouettes)',\n",
       " 'Connectionist Bench (Nettalk Corpus)',\n",
       " 'Connectionist Bench (Sonar, Mines vs. Rocks)',\n",
       " 'Connectionist Bench (Vowel Recognition - Deterding Data)',\n",
       " 'Economic Sanctions',\n",
       " 'Protein Data',\n",
       " 'Cloud',\n",
       " 'CalIt2 Building People Counts',\n",
       " 'Dodgers Loop Sensor',\n",
       " 'Poker Hand',\n",
       " 'MAGIC Gamma Telescope',\n",
       " 'UJI Pen Characters',\n",
       " 'Mammographic Mass',\n",
       " 'Forest Fires',\n",
       " 'Reuters Transcribed Subset',\n",
       " 'Bag of Words',\n",
       " 'Concrete Compressive Strength',\n",
       " 'Hill-Valley',\n",
       " 'Arcene',\n",
       " 'Dexter',\n",
       " 'Dorothea',\n",
       " 'Gisette',\n",
       " 'Madelon',\n",
       " 'Ozone Level Detection',\n",
       " 'Abscisic Acid Signaling Network',\n",
       " 'Parkinsons',\n",
       " 'Character Trajectories',\n",
       " 'Blood Transfusion Service Center',\n",
       " 'UJI Pen Characters (Version 2)',\n",
       " 'Semeion Handwritten Digit',\n",
       " 'SECOM',\n",
       " 'Plants',\n",
       " 'Libras Movement',\n",
       " 'Concrete Slump Test',\n",
       " 'Communities and Crime',\n",
       " 'Acute Inflammations',\n",
       " 'Wine Quality',\n",
       " 'URL Reputation',\n",
       " 'p53 Mutants',\n",
       " 'Parkinsons Telemonitoring',\n",
       " 'Demospongiae',\n",
       " 'Opinosis Opinion ⁄ Review',\n",
       " 'Breast Tissue',\n",
       " 'Cardiotocography',\n",
       " 'Wall-Following Robot Navigation Data',\n",
       " 'Spoken Arabic Digit',\n",
       " 'Localization Data for Person Activity',\n",
       " 'AutoUniv',\n",
       " 'Steel Plates Faults',\n",
       " 'MiniBooNE particle identification',\n",
       " 'YearPredictionMSD',\n",
       " 'PEMS-SF',\n",
       " 'OpinRank Review Dataset',\n",
       " 'Relative location of CT slices on axial axis',\n",
       " 'Online Handwritten Assamese Characters Dataset',\n",
       " 'PubChem Bioassay Data',\n",
       " 'Record Linkage Comparison Patterns',\n",
       " 'Communities and Crime Unnormalized',\n",
       " 'Vertebral Column',\n",
       " 'EMG Physical Action Data Set',\n",
       " 'Vicon Physical Action Data Set',\n",
       " 'Amazon Commerce reviews set',\n",
       " 'Amazon Access Samples',\n",
       " 'Reuter_50_50',\n",
       " 'Farm Ads',\n",
       " 'DBWorld e-mails',\n",
       " 'KEGG Metabolic Relation Network (Directed)',\n",
       " 'KEGG Metabolic Reaction Network (Undirected)',\n",
       " 'Bank Marketing',\n",
       " 'YouTube Comedy Slam Preference Data',\n",
       " 'Gas Sensor Array Drift Dataset',\n",
       " 'ILPD (Indian Liver Patient Dataset)',\n",
       " 'OPPORTUNITY Activity Recognition',\n",
       " 'Nomao',\n",
       " 'SMS Spam Collection',\n",
       " 'Skin Segmentation',\n",
       " 'Planning Relax',\n",
       " 'PAMAP2 Physical Activity Monitoring',\n",
       " 'Restaurant & consumer data',\n",
       " 'CNAE-9',\n",
       " 'Individual household electric power consumption',\n",
       " 'seeds',\n",
       " 'Northix',\n",
       " 'QtyT40I10D100K',\n",
       " 'Legal Case Reports',\n",
       " 'Human Activity Recognition Using Smartphones',\n",
       " 'One-hundred plant species leaves data set',\n",
       " 'Energy efficiency',\n",
       " 'Yacht Hydrodynamics',\n",
       " 'Fertility',\n",
       " 'Daphnet Freezing of Gait',\n",
       " '3D Road Network (North Jutland, Denmark)',\n",
       " 'ISTANBUL STOCK EXCHANGE',\n",
       " 'Buzz in social media',\n",
       " 'First-order theorem proving',\n",
       " 'Wearable Computing: Classification of Body Postures and Movements (PUC-Rio)',\n",
       " 'Gas sensor arrays in open sampling settings',\n",
       " 'Climate Model Simulation Crashes',\n",
       " 'MicroMass',\n",
       " 'QSAR biodegradation',\n",
       " 'BLOGGER',\n",
       " 'Daily and Sports Activities',\n",
       " 'User Knowledge Modeling',\n",
       " 'Reuters RCV1 RCV2 Multilingual, Multiview Text Categorization Test collection',\n",
       " 'NYSK',\n",
       " 'Turkiye Student Evaluation',\n",
       " \"ser Knowledge Modeling Data (Students' Knowledge Levels on DC Electrical Machines)\",\n",
       " 'EEG Eye State',\n",
       " 'Physicochemical Properties of Protein Tertiary Structure',\n",
       " 'seismic-bumps',\n",
       " 'banknote authentication',\n",
       " 'USPTO Algorithm Challenge, run by NASA-Harvard Tournament Lab and TopCoder Problem: Pat',\n",
       " 'YouTube Multiview Video Games Dataset',\n",
       " 'Gas Sensor Array Drift Dataset at Different Concentrations',\n",
       " 'Activities of Daily Living (ADLs) Recognition Using Binary Sensors',\n",
       " 'SkillCraft1 Master Table Dataset',\n",
       " 'Weight Lifting Exercises monitored with Inertial Measurement Units',\n",
       " 'SML2010',\n",
       " 'Bike Sharing Dataset',\n",
       " 'Predict keywords activities in a online social media',\n",
       " 'Thoracic Surgery Data',\n",
       " 'EMG dataset in Lower Limb',\n",
       " 'SUSY',\n",
       " 'HIGGS',\n",
       " 'Qualitative_Bankruptcy',\n",
       " 'LSVT Voice Rehabilitation',\n",
       " 'Dataset for ADL Recognition with Wrist-worn Accelerometer',\n",
       " 'Wilt',\n",
       " 'User Identification From Walking Activity',\n",
       " 'Activity Recognition from Single Chest-Mounted Accelerometer',\n",
       " 'Leaf',\n",
       " 'Dresses_Attribute_Sales',\n",
       " 'Tamilnadu Electricity Board Hourly Readings',\n",
       " 'Airfoil Self-Noise',\n",
       " 'Wholesale customers',\n",
       " 'Twitter Data set for Arabic Sentiment Analysis',\n",
       " 'Combined Cycle Power Plant',\n",
       " 'Urban Land Cover',\n",
       " 'Diabetes 130-US hospitals for years 1999-2008',\n",
       " 'Bach Choral Harmony',\n",
       " 'StoneFlakes',\n",
       " 'Tennis Major Tournament Match Statistics',\n",
       " 'Parkinson Speech Dataset with Multiple Types of Sound Recordings',\n",
       " 'Gesture Phase Segmentation',\n",
       " 'Perfume Data',\n",
       " 'BlogFeedback',\n",
       " 'REALDISP Activity Recognition Dataset',\n",
       " 'Newspaper and magazine images segmentation dataset',\n",
       " 'AAAI 2014 Accepted Papers',\n",
       " 'Gas sensor array under flow modulation',\n",
       " 'Gas sensor array exposed to turbulent gas mixtures',\n",
       " 'UJIIndoorLoc',\n",
       " 'Sentence Classification',\n",
       " 'Dow Jones Index',\n",
       " 'sEMG for Basic Hand movements',\n",
       " 'AAAI 2013 Accepted Papers',\n",
       " 'Geographical Original of Music',\n",
       " 'Condition Based Maintenance of Naval Propulsion Plants',\n",
       " 'Grammatical Facial Expressions',\n",
       " 'NoisyOffice',\n",
       " 'MHEALTH Dataset',\n",
       " 'Student Performance',\n",
       " 'ElectricityLoadDiagrams20112014',\n",
       " 'Gas sensor array under dynamic gas mixtures',\n",
       " 'microblogPCU',\n",
       " 'Firm-Teacher_Clave-Direction_Classification',\n",
       " 'Dataset for Sensorless Drive Diagnosis',\n",
       " 'TV News Channel Commercial Detection Dataset',\n",
       " 'Phishing Websites',\n",
       " 'Greenhouse Gas Observing Network',\n",
       " 'Diabetic Retinopathy Debrecen Data Set',\n",
       " 'HIV-1 protease cleavage',\n",
       " 'Sentiment Labelled Sentences',\n",
       " 'Online News Popularity',\n",
       " 'Forest type mapping',\n",
       " 'wiki4HE',\n",
       " 'Online Video Characteristics and Transcoding Time Dataset',\n",
       " 'Chronic_Kidney_Disease',\n",
       " 'Machine Learning based ZZAlpha Ltd. Stock Recommendations 2012-2014',\n",
       " 'Folio',\n",
       " 'Taxi Service Trajectory - Prediction Challenge, ECML PKDD 2015',\n",
       " 'Cuff-Less Blood Pressure Estimation',\n",
       " 'Smartphone-Based Recognition of Human Activities and Postural Transitions',\n",
       " 'Mice Protein Expression',\n",
       " 'UJIIndoorLoc-Mag',\n",
       " 'Heterogeneity Activity Recognition',\n",
       " 'Educational Process Mining (EPM): A Learning Analytics Data Set',\n",
       " 'HEPMASS',\n",
       " 'Indoor User Movement Prediction from RSS data',\n",
       " 'Open University Learning Analytics dataset',\n",
       " 'default of credit card clients',\n",
       " 'Mesothelioma’s disease data set',\n",
       " 'Online Retail',\n",
       " 'SIFT10M',\n",
       " 'GPS Trajectories',\n",
       " 'Detect Malacious Executable(AntiVirus)',\n",
       " 'Occupancy Detection',\n",
       " 'Improved Spiral Test Using Digitized Graphics Tablet for Monitoring Parkinson’s Disease',\n",
       " 'News Aggregator',\n",
       " 'Air Quality',\n",
       " 'Twin gas sensor arrays',\n",
       " 'Gas sensors for home activity monitoring',\n",
       " 'Facebook Comment Volume Dataset',\n",
       " 'Smartphone Dataset for Human Activity Recognition (HAR) in Ambient Assisted Living (AAL)',\n",
       " 'Polish companies bankruptcy data',\n",
       " 'Activity Recognition system based on Multisensor data fusion (AReM)',\n",
       " 'Dota2 Games Results',\n",
       " 'Facebook metrics',\n",
       " 'UbiqLog (smartphone lifelogging)',\n",
       " 'NIPS Conference Papers 1987-2015',\n",
       " 'HTRU2',\n",
       " 'Drug consumption (quantified)',\n",
       " 'Appliances energy prediction',\n",
       " 'Miskolc IIS Hybrid IPS',\n",
       " 'KDC-4007 dataset Collection',\n",
       " 'Geo-Magnetic field and WLAN dataset for indoor localisation from wristband and smartphone',\n",
       " 'DrivFace',\n",
       " 'Website Phishing',\n",
       " 'YouTube Spam Collection',\n",
       " 'Beijing PM2.5 Data',\n",
       " 'Cargo 2000 Freight Tracking and Tracing',\n",
       " 'Cervical cancer (Risk Factors)',\n",
       " 'Quality Assessment of Digital Colposcopies',\n",
       " 'KASANDR',\n",
       " 'FMA: A Dataset For Music Analysis',\n",
       " 'Air quality',\n",
       " 'Epileptic Seizure Recognition',\n",
       " 'Devanagari Handwritten Character Dataset',\n",
       " 'Stock portfolio performance',\n",
       " 'MoCap Hand Postures',\n",
       " 'Early biomarkers of Parkinson�s disease based on natural connected speech',\n",
       " 'Data for Software Engineering Teamwork Assessment in Education Setting',\n",
       " 'PM2.5 Data of Five Chinese Cities',\n",
       " 'Parkinson Disease Spiral Drawings Using Digitized Graphics Tablet',\n",
       " 'Sales_Transactions_Dataset_Weekly',\n",
       " 'Las Vegas Strip',\n",
       " 'Eco-hotel',\n",
       " 'MEU-Mobile KSD',\n",
       " 'Crowdsourced Mapping',\n",
       " 'gene expression cancer RNA-Seq',\n",
       " 'Hybrid Indoor Positioning Dataset from WiFi RSSI, Bluetooth and magnetometer',\n",
       " 'chestnut – LARVIC',\n",
       " 'Burst Header Packet (BHP) flooding attack on Optical Burst Switching (OBS) Network',\n",
       " 'Motion Capture Hand Postures',\n",
       " 'Anuran Calls (MFCCs)',\n",
       " 'TTC-3600: Benchmark dataset for Turkish text categorization',\n",
       " 'Gastrointestinal Lesions in Regular Colonoscopy',\n",
       " 'Daily Demand Forecasting Orders',\n",
       " 'Paper Reviews',\n",
       " 'extention of Z-Alizadeh sani dataset',\n",
       " 'Z-Alizadeh Sani',\n",
       " 'Dynamic Features of VirusShare Executables',\n",
       " 'IDA2016Challenge',\n",
       " 'DSRC Vehicle Communications',\n",
       " 'Mturk User-Perceived Clusters over Images',\n",
       " 'Character Font Images',\n",
       " 'DeliciousMIL: A Data Set for Multi-Label Multi-Instance Learning with Instance Labels',\n",
       " 'Autistic Spectrum Disorder Screening Data for Children',\n",
       " 'Autistic Spectrum Disorder Screening Data for Adolescent',\n",
       " 'APS Failure at Scania Trucks',\n",
       " 'Wireless Indoor Localization',\n",
       " 'HCC Survival',\n",
       " 'CSM (Conventional and Social Media Movies) Dataset 2014 and 2015',\n",
       " 'University of Tehran Question Dataset 2016 (UTQD.2016)',\n",
       " 'Autism Screening Adult',\n",
       " 'Activity recognition with healthy older people using a batteryless wearable sensor',\n",
       " 'Immunotherapy Dataset',\n",
       " 'Cryotherapy Dataset',\n",
       " 'OCT data & Color Fundus Images of Left & Right Eyes',\n",
       " 'Discrete Tone Image Dataset',\n",
       " 'News Popularity in Multiple Social Media Platforms',\n",
       " 'Ultrasonic flowmeter diagnostics',\n",
       " 'ICMLA 2014 Accepted Papers Data Set',\n",
       " 'BLE RSSI Dataset for Indoor localization and Navigation',\n",
       " 'Container Crane Controller Data Set',\n",
       " 'Residential Building Data Set',\n",
       " 'Health News in Twitter',\n",
       " 'chipseq',\n",
       " 'SGEMM GPU kernel performance',\n",
       " 'Repeat Consumption Matrices',\n",
       " 'detection_of_IoT_botnet_attacks_N_BaIoT',\n",
       " 'Absenteeism at work',\n",
       " 'SCADI',\n",
       " 'Condition monitoring of hydraulic systems',\n",
       " 'Carbon Nanotubes',\n",
       " 'Optical Interconnection Network',\n",
       " 'Sports articles for objectivity analysis',\n",
       " 'Breast Cancer Coimbra',\n",
       " 'GNFUV Unmanned Surface Vehicles Sensor Data',\n",
       " 'Dishonest Internet users Dataset',\n",
       " 'Victorian Era Authorship Attribution',\n",
       " 'Simulated Falls and Daily Living Activities Data Set',\n",
       " 'Multimodal Damage Identification for Humanitarian Computing',\n",
       " 'EEG Steady-State Visual Evoked Potential Signals',\n",
       " 'Roman Urdu Data Set',\n",
       " 'Avila',\n",
       " 'PANDOR',\n",
       " 'Drug Review Dataset (Druglib.com)',\n",
       " 'Drug Review Dataset (Drugs.com)',\n",
       " 'Physical Unclonable Functions',\n",
       " 'Superconductivty Data',\n",
       " 'WESAD (Wearable Stress and Affect Detection)',\n",
       " 'GNFUV Unmanned Surface Vehicles Sensor Data Set 2',\n",
       " 'Student Academics Performance',\n",
       " 'Online Shoppers Purchasing Intention Dataset',\n",
       " 'PMU-UD',\n",
       " \"Parkinson's Disease Classification\",\n",
       " 'Electrical Grid Stability Simulated Data',\n",
       " 'Caesarian Section Classification Dataset',\n",
       " 'BAUM-1',\n",
       " 'BAUM-2',\n",
       " 'Audit Data',\n",
       " 'BuddyMove Data Set',\n",
       " 'Real estate valuation data set',\n",
       " 'Early biomarkers of Parkinson’s disease based on natural connected speech Data Set',\n",
       " 'Somerville Happiness Survey',\n",
       " '2.4 GHZ Indoor Channel Measurements',\n",
       " 'EMG data for gestures',\n",
       " 'Parking Birmingham',\n",
       " 'Behavior of the urban traffic of the city of Sao Paulo in Brazil',\n",
       " 'Travel Reviews',\n",
       " 'Tarvel Review Ratings',\n",
       " 'Rice Leaf Diseases',\n",
       " 'Gas sensor array temperature modulation',\n",
       " 'Facebook Live Sellers in Thailand',\n",
       " 'Parkinson Dataset with replicated acoustic features',\n",
       " 'Metro Interstate Traffic Volume',\n",
       " 'Query Analytics Workloads Dataset',\n",
       " 'Wave Energy Converters',\n",
       " 'PPG-DaLiA',\n",
       " 'Alcohol QCM Sensor Dataset',\n",
       " 'Divorce Predictors data set',\n",
       " 'Incident management process enriched event log',\n",
       " 'Opinion Corpus for Lebanese Arabic Reviews (OCLAR)',\n",
       " 'MEx',\n",
       " 'Beijing Multi-Site Air-Quality Data',\n",
       " 'Online Retail II',\n",
       " 'Hepatitis C Virus (HCV) for Egyptian patients',\n",
       " 'QSAR fish toxicity',\n",
       " 'QSAR aquatic toxicity',\n",
       " 'Human Activity Recognition from Continuous Ambient Sensor Data',\n",
       " 'WISDM Smartphone and Smartwatch Activity and Biometrics Dataset',\n",
       " 'QSAR oral toxicity',\n",
       " 'QSAR androgen receptor',\n",
       " 'QSAR Bioconcentration classes dataset',\n",
       " 'QSAR fish bioconcentration factor (BCF)',\n",
       " 'A study of Asian Religious and Biblical Texts',\n",
       " 'Real-time Election Results: Portugal 2019',\n",
       " 'Bias correction of numerical prediction model temperature forecast',\n",
       " 'Bar Crawl: Detecting Heavy Drinking',\n",
       " 'Kitsune Network Attack Dataset',\n",
       " 'Shoulder Implant X-Ray Manufacturer Classification',\n",
       " 'Speaker Accent Recognition',\n",
       " 'Heart failure clinical records',\n",
       " 'Deepfakes: Medical Image Tamper Detection',\n",
       " 'selfBACK',\n",
       " 'South German Credit',\n",
       " 'Exasens',\n",
       " 'Swarm Behaviour',\n",
       " 'Crop mapping using fused optical-radar data set',\n",
       " 'BitcoinHeistRansomwareAddressDataset',\n",
       " 'Facebook Large Page-Page Network',\n",
       " 'Amphibians',\n",
       " 'Early stage diabetes risk prediction dataset.',\n",
       " 'Turkish Spam V01',\n",
       " 'Stock keeping units',\n",
       " 'Demand Forecasting for a store',\n",
       " 'Detect Malware Types',\n",
       " 'Wave Energy Converters',\n",
       " 'Youtube cookery channels viewers comments in Hinglish',\n",
       " 'Pedestrian in Traffic Dataset',\n",
       " 'Cervical Cancer Behavior Risk',\n",
       " 'Sattriya_Dance_Single_Hand_Gestures Dataset',\n",
       " 'Divorce Predictors data set',\n",
       " '3W dataset',\n",
       " 'Malware static and dynamic features VxHeaven and Virus Total',\n",
       " 'Internet Firewall Data',\n",
       " 'User Profiling and Abusive Language Detection Dataset',\n",
       " 'Estimation of obesity levels based on eating habits and physical condition',\n",
       " 'Rice (Cammeo and Osmancik)',\n",
       " 'Vehicle routing and scheduling problems',\n",
       " 'Algerian Forest Fires Dataset',\n",
       " 'Breath Metabolomics',\n",
       " 'Horton General Hospital',\n",
       " 'UrbanGB, urban road accidents coordinates labelled by the urban center',\n",
       " 'Gas Turbine CO and NOx Emission Data Set',\n",
       " 'Activity recognition using wearable physiological measurements',\n",
       " 'clickstream data for online shopping',\n",
       " 'CNNpred: CNN-based stock market prediction using a diverse set of variables',\n",
       " 'Apartment for rent classified',\n",
       " ': Simulated Data set of Iraqi tourism places',\n",
       " 'Nasarian CAD Dataset',\n",
       " 'Monolithic Columns in Troad and Mysia Region',\n",
       " 'Bar Crawl: Detecting Heavy Drinking',\n",
       " 'Seoul Bike Sharing Demand',\n",
       " 'Person Classification Gait Data',\n",
       " 'Shill Bidding Dataset',\n",
       " 'Iranian Churn Dataset',\n",
       " 'Unmanned Aerial Vehicle (UAV) Intrusion Detection',\n",
       " 'Bone marrow transplant: children',\n",
       " 'Exasens',\n",
       " 'COVID-19 Surveillance',\n",
       " 'Refractive errors',\n",
       " 'Shoulder Implant X-Ray Manufacturer Classification',\n",
       " 'CLINC150',\n",
       " 'HCV data',\n",
       " 'Taiwanese Bankruptcy Prediction',\n",
       " 'South German Credit (UPDATE)',\n",
       " 'IIWA14-R820-Gazebo-Dataset-10Trajectories',\n",
       " 'Guitar Chords finger positions',\n",
       " 'Russian Corpus of Biographical Texts',\n",
       " 'Codon usage',\n",
       " 'Intelligent Media Accelerometer and Gyroscope (IM-AccGyro) Dataset',\n",
       " 'Myocardial infarction complications',\n",
       " 'Hungarian Chickenpox Cases',\n",
       " 'Simulated data for survival modelling',\n",
       " 'Student Performance on an entrance examination',\n",
       " 'Chemical Composition of Ceramic Samples',\n",
       " 'Labeled Text Forum Threads Dataset',\n",
       " 'Stock keeping units',\n",
       " 'BLE RSSI dataset for Indoor localization',\n",
       " 'Basketball dataset',\n",
       " 'GitHub MUSAE',\n",
       " 'Anticancer peptides',\n",
       " 'Monolithic Columns in Troad and Mysia Region',\n",
       " 'Gender by Name',\n",
       " 'Iranian Churn Dataset',\n",
       " 'Unmanned Aerial Vehicle (UAV) Intrusion Detection',\n",
       " 'Shoulder Implant Manufacture Classification',\n",
       " 'LastFM Asia Social Network',\n",
       " 'Wheat kernels',\n",
       " 'Productivity Prediction of Garment Employees',\n",
       " 'Multi-view Brain Networks',\n",
       " 'LastFM Asia Social Network',\n",
       " 'Wisesight Sentiment Corpus',\n",
       " 'AI4I 2020 Predictive Maintenance Dataset',\n",
       " 'Dry Bean Dataset',\n",
       " 'in-vehicle coupon recommendation',\n",
       " 'Gait Classification',\n",
       " 'Wikipedia Math Essentials',\n",
       " 'Wikipedia Math Essentials',\n",
       " 'Synchronous Machine Data Set']"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#fetching the datatype\n",
    "try:\n",
    "    datatype=driver.find_elements_by_xpath(\"//p[@class='normal']/td[2]\")\n",
    "    for i in datatype:\n",
    "        data.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    data.append('No details available')\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
